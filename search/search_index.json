{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"GIG Cymru - NHS Wales - Architecture","text":"<p>This site provides NHS Wales architecture related information.</p>"},{"location":"#principles","title":"Principles","text":"<p>See DHCW Architecture Principles</p>"},{"location":"#decisions","title":"Decisions","text":"<p>An Architecture Decision Record (ADR) is a document that captures an important architecture decision made along with its context and consequences.</p> <ul> <li> <p>Why write architecture decision records - By GitHub Engineering</p> </li> <li> <p>A practical overview on Architecture Decision Records: How to start and why this could be your most valuable action as a software architect</p> </li> </ul>"},{"location":"#first-decisions","title":"First Decisions","text":"<p>Our first decisions are for DHCW to utilise achitecture decision records, specify how we will name them and agree the format:</p> <ul> <li> <p>Introduction</p> </li> <li> <p>Use Architecture Decision Records and Structure</p> </li> <li> <p>Architecture Decision Records Naming Convention</p> </li> <li> <p>Format Architecture Decision Records using plaintext Markdown</p> </li> <li> <p>Use Material for MkDocs for Publishing</p> </li> </ul>"},{"location":"#creating-a-new-record","title":"Creating a new record","text":"<p>See Process</p>"},{"location":"containerization/","title":"Containerization","text":"<p>Note</p> <p>Work in Progress</p> <p>Status: first sketch, work in progress, request for collaboration</p> <p>Date: 2025-04-17</p> <p>Governance: To Be Discovered; potentially a combo of this repo participants, DHCW CISO, NHS Wales UCB peers, etc.</p>"},{"location":"containerization/#situation-context-and-problem-statement","title":"Situation - Context and Problem Statement","text":"<p>To support our software engineering teams with reliable, portable, and secure environments for application development, testing, and deployment, we need a consistent approach to containerization, container management, and container deployment.</p> <p>Right now we need:</p> <ul> <li> <p>Capabilities for software engineers to develop software locally in a container.</p> </li> <li> <p>Capabilities for software engineers to download and run software in containers.</p> </li> </ul> <p>Broadly we want to aim for:</p> <ul> <li> <p>Support for infrastructure-as-code and CI/CD pipelines.</p> </li> <li> <p>Demand for rootless and secure containers (developer-friendly, production-safe).</p> </li> <li> <p>Consideration for direct vs. orchestrated container management.</p> </li> <li> <p>Growing interest in serverless runtimes and integration with ephemeral compute.</p> </li> </ul> <p>We must decide on:</p> <ul> <li> <p>Container engine(s) to use (such as Docker, Podman, etc.)</p> </li> <li> <p>How we build, run, and manage containers (locally, in CI/CD/CT, in demos, in production, etc).</p> </li> <li> <p>Deployment methods (manual, automated, orchestrated, serverless, etc).</p> </li> </ul>"},{"location":"containerization/#drivers","title":"Drivers","text":"<ul> <li> <p>Compatibility: Must work well with Git/GitHub, Tofu/Terraform, CI/CD/CT pipelines.</p> </li> <li> <p>Portability: Support across developer machines and CI environments.</p> </li> <li> <p>Flexibility: Support serverless where appropriate.</p> </li> <li> <p>Security: Rootless containers reduce the attack surface.</p> </li> <li> <p>Simplicity: Avoid Kubernetes unless orchestration is absolutely required.</p> </li> </ul>"},{"location":"containerization/#considered-options-and-related-tooling","title":"Considered options and related tooling","text":"<ul> <li> <p>Container implementations: Docker, Podman, any others?</p> </li> <li> <p>Serverless e.g. closed-source platform-specific such as AWS Fargate Serverless Compute, open-source platform-agnostic such as Knative, any others?</p> </li> <li> <p>Direct management (e.g., via systemd or scripts)</p> </li> <li> <p>Orchestration tools: Kubernetes, any others?</p> </li> </ul>"},{"location":"containerization/#summaries-by-chatgpt","title":"Summaries by ChatGPT","text":"<p>Docker is an open-source platform that enables developers to build, package, and run applications in lightweight, portable containers. A container bundles an application with all its dependencies, libraries, and configuration files, ensuring it runs consistently across different environments\u2014from a developer\u2019s laptop to production servers. Docker simplifies software delivery by isolating applications from the underlying infrastructure, reducing conflicts and streamlining DevOps workflows. It includes tools for building container images, managing containers, and orchestrating multi-container applications, and it serves as a foundational technology for modern, microservices-based and cloud-native architectures.</p> <p>Podman is an open-source container management tool that allows users to build, run, and manage containers and pods without requiring a daemon, unlike Docker. Developed by Red Hat, Podman is designed with security and rootless operation in mind, enabling users to run containers as non-root users for better system isolation and compliance. It supports the same container image formats as Docker and offers a compatible command-line interface (<code>podman</code> can often replace <code>docker</code> commands). Podman also supports Kubernetes YAML generation and can manage pods natively, making it a strong choice for secure and standards-compliant container workflows.</p> <p>Kubernetes is an open-source container orchestration platform that automates the deployment, scaling, management, and networking of containerized applications. Originally developed by Google and now maintained by the Cloud Native Computing Foundation (CNCF), Kubernetes allows users to define the desired state of their applications and ensures that the system continuously works to maintain that state. It manages clusters of nodes (servers) and coordinates containers to run efficiently across them, handling load balancing, service discovery, rolling updates, and self-healing in case of failures. Kubernetes is a foundational technology for cloud-native infrastructure, enabling resilient, scalable, and portable application deployments across diverse environments.</p> <p>kubectl is the command-line tool used to interact with Kubernetes clusters, allowing users to deploy applications, inspect and manage cluster resources, and view logs or events. It communicates with the Kubernetes API server to execute commands such as creating pods, scaling deployments, updating configurations, and troubleshooting workloads. The kubectl command is essential for developers and administrators working with Kubernetes, providing a powerful and flexible interface for managing the full lifecycle of containerized applications.</p> <p>Buildah is an open-source command-line tool designed to create and manage container images without requiring a Docker daemon. It enables developers to build container images in a flexible and lightweight manner, either by using a Dockerfile or through direct commands to add files and configure image layers. Buildah is particularly useful in environments where running a full Docker daemon is unnecessary, such as in CI/CD pipelines or Kubernetes setups. It integrates well with other container tools like Podman and can push images to container registries, offering a more efficient and customizable alternative for building and managing container images.</p> <p>Conmon** (short for \"container monitor\") is an open-source tool designed to monitor and manage container processes in a lightweight and efficient manner. It is typically used in conjunction with container runtimes like Podman and Kubernetes to handle the monitoring of container lifecycles, including logging, handling the standard input/output streams, and managing the container\u2019s exit status. Conmon runs as a subprocess alongside the container, ensuring that the container\u2019s logs and process status are properly captured and reported. It provides a minimal, low-overhead solution for container monitoring, focusing on keeping the container's environment clean and efficient without introducing unnecessary complexity.</p> <p>Trivy is an open-source vulnerability and security scanner developed by Aqua Security, designed to detect issues in container images, file systems, and source code repositories. It scans for a wide range of security problems, including OS package vulnerabilities (e.g., in Alpine, Debian, Ubuntu), language-specific package issues (e.g., pip, npm, bundler), misconfigurations in Kubernetes and Docker, exposed secrets, and software licenses. Trivy is lightweight, easy to use, and integrates well into CI/CD pipelines, making it a popular tool for DevSecOps workflows to ensure containers and infrastructure are secure before deployment.</p> <p>Copacetic is an open-source command-line tool developed by Microsoft and hosted under the CNCF Sandbox. It enables DevSecOps teams to patch container image vulnerabilities directly, without the need to rebuild the entire image. By integrating with popular vulnerability scanners like Trivy, Copacetic identifies outdated or vulnerable packages and applies updates as additional layers on top of the existing image. This tool is particularly beneficial for patching inherited base image vulnerabilities or third-party application images without waiting for upstream updates.</p> <p>Harbor is an open-source cloud-native registry project that stores, signs, and scans container images for vulnerabilities, with a focus on security, compliance, and performance in enterprise environments. Developed by VMware and now part of the CNCF (Cloud Native Computing Foundation), Harbor extends Docker Registry with features like role-based access control, image replication across registries, and integration with vulnerability scanners such as Trivy for continuous scanning. It automates security checks on container images as they're pushed or pulled, enabling organizations to enforce policies and maintain a secure software supply chain throughout the development lifecycle.</p> <p>Kind (Kubernetes in Docker) is an open-source tool for running local Kubernetes clusters using Docker container \"nodes.\" Designed primarily for testing and development, Kind allows users to spin up lightweight Kubernetes clusters without needing virtual machines or external cloud infrastructure. It runs each Kubernetes node inside a Docker container, making it ideal for CI/CD pipelines, prototyping, and learning Kubernetes in a controlled, resource-efficient environment. Kind supports multi-node clusters and integrates well with standard Kubernetes tooling like <code>kubectl</code>.</p> <p>Crossplane is an open-source, multi-cloud control plane that enables the management of cloud infrastructure and services using Kubernetes-style declarative APIs. It extends Kubernetes to allow users to provision and manage resources across multiple cloud providers (like AWS, Azure, Google Cloud) and on-prem environments from a single control plane. Crossplane enables infrastructure as code (IaC) by defining resources using Kubernetes manifests, allowing developers to manage everything from databases to networking resources and virtual machines. This unified approach simplifies complex infrastructure management, promotes consistency across cloud environments, and supports a more flexible, scalable architecture for modern cloud-native applications.</p> <p>Rancher is an open-source container management platform that simplifies deploying, managing, and scaling Kubernetes clusters across on-premises, cloud, and hybrid environments. Developed by SUSE, Rancher provides a centralized user interface and API for administering multiple Kubernetes clusters, regardless of where they're running. It offers tools for lifecycle management, access control, monitoring, security policy enforcement, and integrated application catalogs. Rancher streamlines DevOps workflows by abstracting much of the complexity of Kubernetes, making it easier for teams to operate and govern containerized applications at scale.</p> <p>Helm is an open-source package manager for Kubernetes that helps developers and operators define, install, and manage complex Kubernetes applications using reusable, version-controlled templates called charts. A Helm chart bundles all the necessary Kubernetes manifests\u2014like deployments, services, and config maps\u2014into a single package, making it easy to deploy applications consistently across environments. Helm simplifies application lifecycle management by enabling upgrades, rollbacks, and configuration overrides through values files. As a CNCF project, Helm is widely used to streamline Kubernetes operations, reduce manual configuration, and promote best practices in infrastructure as code.</p> <p>Knative is an open-source platform built on Kubernetes that enables the development, deployment, and management of serverless applications. It provides a set of components that abstract away the complexity of managing serverless workloads, allowing developers to focus on writing code without worrying about the underlying infrastructure. Knative includes features like automatic scaling (including scaling to zero), event-driven architecture, and support for both stateless and stateful workloads. It integrates seamlessly with Kubernetes and tools like Istio, offering capabilities for routing, traffic splitting, and service management. Knative is ideal for building modern, cloud-native applications that need to scale dynamically based on demand while leveraging Kubernetes for orchestration.</p> <p>Amazon Web Services (AWS) Fargate is a serverless compute engine for containers that allows users to run containerized applications without having to manage the underlying server infrastructure. Integrated with Amazon ECS (Elastic Container Service) and Amazon EKS (Elastic Kubernetes Service), Fargate automatically provisions, scales, and manages compute resources needed to run containers, so developers can focus on building and deploying applications. With Fargate, there\u2019s no need to choose instance types or manage cluster capacity\u2014users simply define their container requirements, and AWS handles the rest, offering a pay-as-you-go model that improves scalability, security, and operational efficiency.</p> <p>Amazon Web Services (AWS) Elastic Container Service (ECS) is a fully managed container orchestration service provided by AWS, designed to simplify the deployment, management, and scaling of containerized applications. It allows users to run and manage Docker containers across a cluster of virtual machines, using tasks and services to automate container deployment, scaling, and networking. ECS integrates seamlessly with other AWS services like Elastic Load Balancing, IAM, and CloudWatch, providing a secure and scalable platform for containerized applications. ECS offers two launch types: EC2 (for running containers on EC2 instances) and Fargate (for serverless container management), giving users flexibility in how they manage their container infrastructure.</p> <p>Amazon Web Services (AWS) Elastic Kubernetes Service (Amazon EKS) is a managed service provided by AWS that simplifies the deployment, management, and scaling of containerized applications using Kubernetes. EKS automatically handles tasks like cluster provisioning, patching, and scaling, allowing developers to focus on building and deploying applications rather than managing infrastructure. It integrates seamlessly with other AWS services such as Elastic Load Balancing, IAM, and Amazon VPC, providing security, networking, and monitoring capabilities. EKS supports both AWS infrastructure and on-premises environments, making it ideal for running scalable, resilient containerized applications in a secure and managed Kubernetes environment.</p> <p>Google Kubernetes Engine (GKE) is a fully managed Kubernetes service provided by Google Cloud, designed to simplify the deployment, management, and scaling of containerized applications using Kubernetes. GKE handles the complexities of Kubernetes, such as managing the control plane, upgrades, and scaling, while giving users full control over the worker nodes and container workloads. It offers integrated features like auto-scaling, monitoring, security, and load balancing, as well as deep integration with other Google Cloud services, enabling seamless DevOps workflows and efficient cloud-native application management. GKE provides a highly available and reliable platform for running applications at scale, making it one of the most popular managed Kubernetes services in the cloud.</p> <p>Microsoft Azure Kubernetes Service (AKS) is a managed Kubernetes service provided by Microsoft Azure that simplifies the deployment, management, and scaling of containerized applications using Kubernetes. With AKS, Microsoft handles the Kubernetes control plane, including updates, patching, and scaling, allowing developers to focus on building and running their applications rather than managing infrastructure. AKS integrates with Azure\u2019s ecosystem, providing built-in monitoring, security features, and seamless integration with other Azure services like Azure Active Directory, networking, and storage. It supports automated scaling, load balancing, and rolling updates, making it easier to deploy, maintain, and scale applications in a cloud-native environment.</p> <p>ArgoCD is an open-source continuous delivery (CD) tool for Kubernetes that automates the deployment of applications using GitOps principles. It enables declarative management of Kubernetes resources by linking them to Git repositories, where application configurations and manifests are stored. ArgoCD continuously monitors these repositories for changes and automatically applies them to the Kubernetes clusters, ensuring the deployed state matches the desired configuration in Git. It provides a user-friendly web interface and CLI for managing applications, visualizing deployment status, and rolling back changes when necessary. By integrating with Git as the source of truth, ArgoCD ensures a secure, auditable, and automated workflow for Kubernetes application delivery.</p> <p>Portainer is an open-source, lightweight container management platform that simplifies the deployment, management, and monitoring of Docker and Kubernetes environments. It provides a user-friendly web interface for managing containerized applications, allowing users to easily create, configure, and monitor containers, images, networks, and volumes. Portainer supports both Docker and Kubernetes clusters, offering a unified management interface for users who may work with different container orchestration systems. It also provides role-based access control (RBAC) and a variety of features to streamline DevOps workflows, making it a popular choice for both beginners and experienced developers looking to manage containers in a simplified, accessible way.</p>"},{"location":"containerization/#evaluation","title":"Evaluation","text":""},{"location":"containerization/#docker","title":"Docker","text":"<p>Pros:</p> <ul> <li> <p>Ubiquity</p> </li> <li> <p>Wide ecosystem</p> </li> <li> <p>Docker Compose is very handy.</p> </li> </ul> <p>Cons:</p> <ul> <li> <p>Requires daemon</p> </li> <li> <p>Default setup needs root access unless configured</p> </li> <li> <p>Licensing shenanigans</p> </li> </ul>"},{"location":"containerization/#podman","title":"Podman","text":"<p>Pros:</p> <ul> <li> <p>Rootless</p> </li> <li> <p>Daemonless</p> </li> <li> <p>OCI-compatible</p> </li> <li> <p>Docker CLI compatible</p> </li> </ul> <p>Cons:</p> <ul> <li> <p>Some ecosystem gaps</p> </li> <li> <p>Fewer tutorials and LLM prompts</p> </li> </ul>"},{"location":"containerization/#serverless-lambda-knative","title":"Serverless (Lambda, Knative)","text":"<p>Pros:</p> <ul> <li> <p>Auto-scaling</p> </li> <li> <p>No infra to manage.</p> </li> </ul> <p>Cons:</p> <ul> <li> <p>Cold start latency</p> </li> <li> <p>Limited runtime control</p> </li> <li> <p>Vendor-specific setup doesn't lend itself to multi-cloud resilience</p> </li> <li> <p>No overlap with local tooling</p> </li> </ul>"},{"location":"containerization/#direct-management-eg-via-systemd-or-scripts","title":"Direct management (e.g., via systemd or scripts)","text":"<p>Pros:</p> <ul> <li> <p>Lightweight, fast, easy</p> </li> <li> <p>Excellent for local software engineering</p> </li> </ul> <p>Cons:</p> <ul> <li> <p>Lacks orchestration</p> </li> <li> <p>Not scalable</p> </li> <li> <p>Not easy in the cloud</p> </li> </ul>"},{"location":"containerization/#kubernetes-orchestration-tools","title":"Kubernetes / Orchestration tools","text":"<p>Pros:</p> <ul> <li> <p>By far the most powerful, scalable, and capable, for professional operations teams</p> </li> <li> <p>Definitely where we want to be aiming in the next couple of years</p> </li> </ul> <p>Cons:</p> <ul> <li> <p>Complex - probably too complex to ask mid-level software engineers to pick up for a non-ops project</p> </li> <li> <p>Overhead - probably too big a lift right now for us, because we don't have the networking setups</p> </li> </ul>"},{"location":"containerization/#implications","title":"Implications","text":"<ul> <li> <p>Software engineering developer environments should transition to containers where feasible.</p> </li> <li> <p>CI/CD/CT pipelines will include container build steps with containers, depending on runner environment.</p> </li> <li> <p>Documentation and training needs to be created for software engineers to learn about containerization.</p> </li> <li> <p>For more-complex deployment needs, we'll need to create a path for   containerization leading to eventual use of Kubernetes or serverless platforms   depending on cost/performance trade-offs.</p> </li> </ul>"},{"location":"containerization/#references","title":"References","text":"<ul> <li> <p>Podman Documentation</p> </li> <li> <p>Docker Documentation</p> </li> <li> <p>Open Container Initiative (OCI)</p> </li> <li> <p>AWS Lambda Container Support</p> </li> </ul>"},{"location":"containerization/#decision","title":"Decision","text":"<p>We will adopt the following containerization and management strategy:</p> <p>Container Engine:</p> <ul> <li> <p>Use Podman as the default engine for local development and rootless use cases.</p> </li> <li> <p>Support Docker where Podman isn't viable, such as a project already using Docker Compose.</p> </li> </ul> <p>Container Image Management:</p> <ul> <li> <p>Use OCI-compliant image builds.</p> </li> <li> <p>Store and retrieve images via internal and external registries (e.g., ECR, Docker Hub, GitHub Container Registry).</p> </li> </ul> <p>Execution and Management:</p> <ul> <li> <p>For local development: encourage Podman rootless containers to increase security and reduce dependency on Docker daemon.</p> </li> <li> <p>For CI/CD/CT: Use containerized runners (e.g., GitHub Actions, GitLab Runners) with Podman setups depending on environment support.</p> </li> <li> <p>For ephemeral execution: leverage serverless runtimes when the workload fits.</p> </li> </ul> <p>Infrastructure as Code Integration:</p> <ul> <li> <p>Container lifecycle (build, deploy, destroy) will be managed through IaC tools such as Tofu/Terraform, or similar complementary technologies such as Dagger, Pulumi or Ansible. We intend to do a complementary ADR for these.</p> </li> <li> <p>All container-related infra should be declarative and version-controlled.</p> </li> </ul>"},{"location":"coordinated-vulnerability-disclosure/","title":"Coordinated Vulnerability Disclosure (CVD)","text":"<p>EXPERIMENT BY IGDC-DHCW - DRAFT - WORK IN PROGRESS - REQUEST FOR COMMENTS</p>"},{"location":"coordinated-vulnerability-disclosure/#situation-context-and-problem-statement","title":"Situation - Context and Problem Statement","text":"<p>The upcoming IGDC-DHCW emergency department module (EDM) and its exploratory authentication service (WAuth) are work in progress. Currently these don't seem to have a process for coordinated vulnerability disclosure (CVD), such as if/how any person could report a potential security vulnerability.</p> <p>The purpose of this document is to open up discussion of a CVD process for the EDM and WAuth services. Then ideally to implement it for those services. Then ideally to extend the CVD to additional IGDC-DHCW services.</p> <p>The existing guidance from NHS Wales info sec that Joel has found (thus far) doesn't seem to say anything about how people will do security disclosure.</p>"},{"location":"coordinated-vulnerability-disclosure/#background-decision-drivers","title":"Background - Decision Drivers","text":"<p>When a security vulnerability is discovered in a service, it is important to coordinate the disclosure of that vulnerability to the service's users. This is to ensure that the vulnerability is fixed as soon as possible, and that the service's users are not exposed to any risk.</p> <p>Many popular websites handle this by having a \"security\" notice on their web page footers, and also by publishing a security process such as how to report a bug, how to report a potential vulnerability, etc. These notices help service providers work better with the public (and internal staff) to handle security issues effectively.</p> <p>A \"Coordinated Vulnerability Disclosure\" (CVD) is a process where security vulnerabilities are disclosed to the public only after the responsible parties (like vendors) have had sufficient time to address and mitigate the issue, ensuring a coordinated and timely approach to patching and remediation.</p> <p>Background reading:</p> <p>https://english.ncsc.nl/publications/publications/2019/juni/01/coordinated-vulnerability-disclosure-the-guideline</p> <ul> <li> <p>Coordinated Vulnerability Disclosure - The Guideline - By National Cyber Security Centre - The Netherlands</p> </li> <li> <p>Coordinated Vulnerability Disclosure - GitHub repo - By Joel</p> </li> <li> <p>Wikipedia: Coordinated_vulnerability_disclosure</p> </li> <li> <p>NHS Wales Information Security Policy</p> </li> <li> <p>NHS Wales Information Security Policy for Primary Care Service Provider</p> </li> <li> <p>NIST Cybersecurity Framework</p> </li> </ul>"},{"location":"coordinated-vulnerability-disclosure/#govuk-national-cyber-security-centre","title":"GOV.UK National Cyber Security Centre","text":"<p>Links:</p> <ul> <li> <p>GOV.UK National Cyber Security Centre: vulnerability management reporting disclosure</p> </li> <li> <p>GitHub.com/UKNCSC</p> </li> </ul> <p>Joel has asked the NCSC for help and guidance via their typical web form, such as if/how to use NCSC CVD.</p> <ul> <li> <p>Joel's first skim of NCSC doesn't turns up lots about generic disclosure, but nothing about specific CVD.</p> </li> <li> <p>Joel's first skim of NCSC shows everything is IMHO typical practices throughout industry, i.e. there's nothing notable or differentiating. Therefore it looks fine to align, reference, etc., in general.</p> </li> <li> <p>The NCSC process has a few areas that are anti-CVD, such as telling the person what to do, rather than respecting the person's perspective; Joel's guess is this is merely an outdated document, rather than a countermand policy. Joel has asked the NCSC to clarify and ideally to correct.</p> </li> </ul> <p>The NCSC recommendations that look to be most relevant and useful and best practice:</p> <ul> <li> <p>Create a dedicated security email address for reporting vulnerabilities, using the format of security@example.com, and a confirmation auto-reply that can provide additional instructions.</p> </li> <li> <p>Create a website file <code>security.txt</code> in the root directory of the website, and in the subdirectory <code>.well-known</code>, that is public i.e. accessible at https://example.com/security.txt and https://example.com/.well-known/security.txt, that explains the organization security policy.</p> </li> <li> <p>Create a PGP key for the security email address, and publish it in the <code>security.txt</code> file.</p> </li> </ul> <p>Joel tested the NCSC recommendations with our closest peers on 2025-03-25 and these email addresses all have issues:</p> <ul> <li> <p>Email to security@nhs.uk fails with this message: Relay access denied (in reply to RCPT TO command).</p> </li> <li> <p>Email to security@wales.nhs.uk does not provide any receipt confirmation e.g. additional instructions.</p> </li> <li> <p>Email to security@ncsc.gov.uk does not provide any receipt confirmation e.g. additional instructions.</p> </li> </ul> <p>Joel tested these links on 2025-03-25:</p> <ul> <li> <p>NCSC:</p> </li> <li> <p>https://www.ncsc.gov.uk/.well-known/security.txt \u2192 success and has a PGP key (which is great!)</p> </li> <li> <p>https://www.ncsc.gov.uk/security.txt \u2192 404</p> </li> <li> <p>NHS UK:</p> </li> <li> <p>https://www.nhs.uk/.well-known/security.txt \u2192 found, but forces the reporter to sign up with HackerOne, which is a for-profit service, and a blocker, and a security risk, and a cross-border political problem.</p> </li> <li> <p>https://nhs.uk/security.txt \u2192 404</p> </li> <li> <p>NHS England:</p> </li> <li> <p>https://www.england.nhs.uk/security.txt \u2192 found, but forces the reporter to sign up with HackerOne, which is a for-profit service, and also a de-anonymization risk.</p> </li> <li> <p>NHS Wales:</p> </li> <li> <p>https://wales.nhs.uk/security.txt \u2192 404</p> </li> <li> <p>https://wales.nhs.uk/.well-known/security.txt \u2192 404</p> </li> <li> <p>https://nhs.wales/security.txt \u2192 failure due to no root record</p> </li> <li> <p>https://nhs.wales/.well-known/security.txt \u2192 failure due to no root record</p> </li> <li> <p>https://www.nhs.wales/security.txt \u2192 404</p> </li> <li> <p>https://www.nhs.wales/.well-known/security.txt \u2192 404</p> </li> <li> <p>NHS Wales DHCW:</p> </li> <li> <p>https://dhcw.nhs.wales/security.txt \u2192 404</p> </li> <li> <p>https://dhcw.nhs.wales/.well-known/security.txt \u2192 404</p> </li> <li> <p>NHS Scotland:</p> </li> <li> <p>https://www.scot.nhs.uk/.well-known/security.txt \u2192 Success. But no PGP key. But forces HackerOne.</p> </li> <li> <p>NSCNI:</p> </li> <li> <p>https://www.hscni.net/security.txt \u2192 404</p> </li> <li> <p>https://www.hscni.net/.well-known/security.txt \u2192 404</p> </li> </ul> <p>What the above testing clearly shows is that UK NHS Wales is currently not harmonizing with UK NCSC (nor NL NCSC) at all, and more broadly that NHS4 is not harmonizing completely with NCSC. We should aim to fix this, so that do do harmonize with UK NCSC and NL NCSC.</p>"},{"location":"coordinated-vulnerability-disclosure/#nhs-england-nhs-scotland","title":"NHS England &amp; NHS Scotland","text":"<p>NHS England and NHS Scotland have security policies that are derived from UK NCSC as above. Joel's skim didn't turn up anything notable or differentiating.</p> <p>However, there are multiple weaknesses as compared to NCSC:</p> <ul> <li> <p>No PGP key in the file <code>security.txt</code>.</p> </li> <li> <p>Redirect to HackerOne, which is a for-profit service, and a blocker, and a security risk, and a cross-border political problem.</p> </li> </ul>"},{"location":"coordinated-vulnerability-disclosure/#pgp-signing","title":"PGP signing","text":"<p>Pretty Good Privacy (PGP) signing is an industry standard for secure email messaging.</p> <p>For reference, a typical PGP signed message looks like this, and would/could be included in the file <code>security.txt</code> as well as anywhere else the organization wishes to publish secure email instructions.</p> <pre><code>-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA256\n\nCanonical: https://example.com/.well-known/security.txt)\nContact: mailto:security@nexample.com\nPreferred-Languages: en\nEncryption: https://example.com/encryption/\nPolicy: https://example.com/security/\nExpires: 2026-01-01T00:00:00.000Z\n-----BEGIN PGP SIGNATURE-----\n\njqSLotcXiyEu7PY3GBFPrqEUfTdaqBwPFRiQoGHc8RJebdkTDkFQStb322md3M16\n3XBYDO0ArQXGQMQWP1d8lZhdOmiguIvVfWUXemGu3sC6vg7b8RNmtyGcSFpIwStj\nQReSG0XasD9a5yArYvdBMQGcKbN6U0QGNOoCPUs42qjq7X91Rm9MlU6MtGFztcBg\nr4YWAzmnMbEexiTaSPSsf55QFnqxZLI7Ktw8sovfs7wi4b1rNYgu2WMAPS53TGAG\nujGVR8Xx99yyhE3vaBD1BsjJnoPPc1gYcRJK7cbdmxXPgDEZmZOQjoY1GpBeqEkX\nGK3f6h3CtRgBxNEAZdSE4ZfXCdhOOf3D6uldGZaBveIruFtesY3BwmarAdbEr1mi\nuESVHaRz0xj02CSQ4DZfbFoC2OyfgiZLMAxQ4j8NqCPscKTcqegJAHwoD4axdysE\n0QnY8uI0asS3DOm7b6ZnhyY76YZiOQYIKvPLLhRQ2rq8My72IdaI3OGqvI3Q1ku2\njRJvM7V9l61MgFHemdz1RlF5jDQtQFVQN9TVunIA9gebxgLYexGh6sWxNHoPxkgv\n\n-----END PGP SIGNATURE-----\n</code></pre>"},{"location":"coordinated-vulnerability-disclosure/#assessment-considered-options","title":"Assessment - Considered Options","text":"<p>Our #1 option is to involve the CISO team, and let them decide what to do. We're working on this now.</p> <p>Our #2 option is to use the existing work by Joel, which he developed thanks to Colin Percival and multiple enterprise clients.</p> <p>We hope to have a Welsh-first option, such as a Welsh-first email address e.g. sediogelwch@gig.cymru. Currently the internal ops team says this capability is a ways in the future.</p> <p>We hope to have an English-second option, such as an English-second email address e.g. security@wales.nhs.uk. It's possible that our group already has this, because a probe email to that address didn't bounce back. TBD.</p> <p>We hope to add more options here.</p>"},{"location":"coordinated-vulnerability-disclosure/#recommendation-decision-outcome","title":"Recommendation - Decision Outcome","text":"<p>TODO as we learn more.</p>"},{"location":"coordinated-vulnerability-disclosure/#consequences","title":"Consequences","text":"<p>TODO as we learn more.</p> <ul> <li>Good, because {positive consequence, e.g., improvement of one or more desired qualities, \u2026}</li> <li>Bad, because {negative consequence, e.g., compromising one or more desired qualities, \u2026}</li> <li>\u2026 </li> </ul>"},{"location":"coordinated-vulnerability-disclosure/#confirmation-optional","title":"Confirmation (Optional)","text":"<p>TODO as we learn more.</p> <p>{Describe how the implementation of/compliance with the ADR can/will be confirmed.}</p>"},{"location":"coordinated-vulnerability-disclosure/#pros-and-cons-of-the-options-optional","title":"Pros and Cons of the Options (Optional)","text":"<p>TODO as we learn more.</p>"},{"location":"coordinated-vulnerability-disclosure/#title-of-option-1","title":"{title of option 1}","text":"<p>{example | description | pointer to more information | \u2026}</p> <ul> <li>Good, because {argument a}</li> <li>Good, because {argument b}</li> </ul> <ul> <li>Neutral, because {argument c}</li> <li>Bad, because {argument d}</li> <li>\u2026 </li> </ul>"},{"location":"coordinated-vulnerability-disclosure/#more-information-optional","title":"More Information (Optional)","text":"<p>TODO as we learn more.</p> <p>{You might want to provide additional evidence/confidence for the decision outcome here and/or document the team agreement on the decision and/or define when/how this decision the decision should be realised and if/when it should be re-visited. Links to other decisions and resources might appear here as well.}</p>"},{"location":"design-authority/dhcw/","title":"Introduction","text":"<p>Documents in this section are architecture decision records for DHCW, the governance of which is via the Technical Design Authority (TDA).</p> <p>See ADR Process.</p> <p>The initial records are:</p> <ul> <li>Use Architecture Decision Records and Structure</li> <li>Architecture Decision Records Naming Conventions</li> <li>Format Architecture Decision Records using plaintext Markdown</li> <li>Use Material for MkDocs for Publishing</li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-record-template/","title":"{Your Title Here}","text":"<p>Info</p> <p>Status: { Proposed | Under Review | Accepted |               Rejected | Superseded   | Deprecated }</p> <p>Level: { 1 - 4 }</p> <p>Updated: { YYYY-MM-DD }</p>"},{"location":"design-authority/dhcw/architecture-decision-record-template/#summary","title":"Summary","text":"<p>{This is the 'executive summary' or 'elevator pitch' for your ADR. In a few concise sentences (typically 2-4), clearly state the core problem, question, or opportunity this ADR addresses. Include a brief hint at the decision made or the area of focus. The goal is to help readers quickly understand what this ADR is about and decide if it's relevant to them, without needing to read the entire document. Think of it as the abstract of a technical paper or a very brief introduction to the main topic.}</p>"},{"location":"design-authority/dhcw/architecture-decision-record-template/#drivers","title":"Drivers","text":"<p>{This section explains why this decision is being made now. Clearly articulate the primary motivations, needs, or problems that necessitate this architectural decision. Think about the underlying reasons and pressures.}</p> <ul> <li>{e.g. We are developing a new feature/capability that needs...}</li> <li>{e.g. We need to improve performance, accessibility, remove debt...}</li> <li>{e.g. Feedback from users suggests...}</li> <li>{e.g. The current approach imposes these limitations...}</li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-record-template/#options","title":"Options","text":"<p>{This is where you list the different options you are considering. Stick to the facts and avoid opinions, the next section covers the analysis. Include a concise description, links to relevant documentation or examples.</p> <p>Include all significant alternatives you explored, even if they were ultimately not chosen. The goal is to give readers a clear, unbiased understanding of each alternative before you dive into the evaluation.}</p>"},{"location":"design-authority/dhcw/architecture-decision-record-template/#option-1-title","title":"{Option 1 Title}","text":"<p>{Describe the option, provide a summary, list the facts, provide links etc.}</p>"},{"location":"design-authority/dhcw/architecture-decision-record-template/#option-n-title","title":"{Option n Title}","text":"<p>...</p>"},{"location":"design-authority/dhcw/architecture-decision-record-template/#options-analysis","title":"Options Analysis","text":"<p>{This is where you critically evaluate each option presented in the Options section. For each option, provide a balanced view of its advantages, disadvantages, and any other relevant considerations or trade-offs. Be specific and, where possible, relate your points back to the Drivers.</p> <p>Consider aspects like:</p> <ul> <li>Cost (development, operational, licensing)</li> <li>Complexity (implementation, maintenance, learning curve)</li> <li>Risks (technical, operational, security)</li> <li>Alignment with architectural principles or existing standards</li> <li>Impact on performance, scalability, usability, maintainability,     security etc.</li> </ul> <p>Include as many Pro/Con/Other statements as required.}</p>"},{"location":"design-authority/dhcw/architecture-decision-record-template/#option-1-assessment","title":"{Option 1 Assessment}","text":"<p>Pro:</p> <ul> <li>{A specific advantage or benefit of this option.}</li> <li>...</li> </ul> <p>Con:</p> <ul> <li>{A specific disadvantage, risk, or cost associated with this option.}</li> <li>...</li> </ul> <p>Other:</p> <ul> <li>{A relevant point that isn't strictly a pro or con.}</li> <li>...</li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-record-template/#option-n-assessment","title":"{Option n Assessment}","text":"<p>...</p>"},{"location":"design-authority/dhcw/architecture-decision-record-template/#recommendation","title":"Recommendation","text":"<p>{This is where you clearly state the final decision, and explicitly name the option that has been selected. Explain in detail why this option was chosen. You should clearly articulate how the chosen option best addresses the Drivers and meets the key requirements or solves the stated problem.}</p>"},{"location":"design-authority/dhcw/architecture-decision-record-template/#consequences","title":"Consequences","text":"<p>{This section is optional.}</p> <p>{Now that a decision has been made what are the expected outcomes and impacts, both positive and negative? What known limitations, costs, or risks are being accepted by making this decision? How will this decision affect different stakeholders, other systems, development practices, operational procedures, or user experience?}</p> <ul> <li> <p>Pro: {A specific positive outcome or benefit expected from this decision.}</p> </li> <li> <p>Con: {A specific accepted downside, cost, or risk resulting from this     decision. }</p> </li> <li> <p>Other: {A consequence that isn't strictly a pro or con.}</p> </li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-record-template/#confirmation","title":"Confirmation","text":"<p>{This section is optional.}</p> <p>{Outline how the implementation of this decision will be verified and how ongoing compliance will be ensured. This helps demonstrate that the decision isn't just theoretical but will be actively put into practice and monitored.</p> <p>How will you check that the decision has been correctly implemented? (e.g., code reviews, specific tests, demonstrations, peer review).</p> <p>How will adherence to this decision be maintained over time? (e.g., automated checks, periodic audits, updates to team guidelines, training).</p> <p>Are there specific metrics or indicators that will show the decision is achieving its intended positive outcomes? (e.g., performance benchmarks, adoption rates, reduction in specific errors, user feedback scores).</p> <p>Who is responsible for overseeing this, and what happens if the decision is not followed?}</p>"},{"location":"design-authority/dhcw/architecture-decision-record-template/#more-information","title":"More Information","text":"<p>{This section is optional.}</p> <p>{Use this section to provide any supplementary information that supports the decision, adds context, or guides future actions. Links to other decisions and resources might appear here as well.</p> <p>You could briefly note who was involved in the decision-making process and if/how consensus was reached. You may also want to suggest a timeframe or specific events that might prompt a re-evaluation of this decision in the future.}</p>"},{"location":"design-authority/dhcw/architecture-decision-record-process/","title":"Architecture Decision Record Process","text":"<p>Warning</p> <p>This process is pending approval from the DHCW Technical Design Authority (TDA)</p>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#introduction","title":"Introduction","text":"<p>This document outlines the process for proposing, developing, collaborating on, and approving Architecture Decision Records (ADRs) within DHCW. The process emphasises collaboration and working in the open whilst minimising the involvement of formal governance bodies (e.g. Technical Design Authority (TDA) and Technical Design Assurance Group (TDAG)) as much as is practicable whilst maintaining suitable levels of assurance and governance.</p> <p>Anyone can propose an ADR and request collaboration to approve a decision. The proposal should clearly articulate the problem and context, and may include a solution or decision if ready. Early engagement is strongly encouraged, so it is expected proposals will be incomplete and very draft when first proposed.</p> <p>There are multiple levels of decision defined, which follow different processes proportionate to their impact/significance.</p> <p>Template</p> <p>The approved ADR template should be used to ensure consistency and completeness.</p>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#when-to-create-an-adr","title":"When to Create an ADR","text":"<p>An ADR should be created for decisions that have a significant impact on the architecture of a system or the technical landscape of DHCW. The primary purpose is to capture the context and rationale behind important decisions for future reference and understanding.</p> <p>Generally, an ADR is justified when a decision:</p> <ul> <li>Affects the structure of a system or multiple systems.</li> <li>Requires coordination or consistency across different teams or projects.</li> <li>Impacts the long-term maintainability, scalability, security, or performance     of a system or service.</li> <li>Changes external interfaces or significant internal APIs.</li> <li>Would benefit future developers, architects, or stakeholders to understand     the \"why\" behind the decision.</li> </ul> <p>While the above guidelines cover many scenarios, an ADR is typically not required for:</p> <ul> <li>Decisions that do not fall into the category of \"Architecture\" (e.g.,     purely project management, administrative, or minor UI design choices).</li> <li>Trivial or routine activities with no lasting architectural impact.</li> <li>Decisions fully covered by existing, well-documented standards, policies,     or established patterns.</li> <li>Temporary workarounds, short-lived experiments, or proofs of concept     that are not intended to be permanent architectural components.</li> <li>Low-risk, self-contained decisions made by a single developer within a     project with no impact outside that immediate scope.</li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#initiation-and-commissioning","title":"Initiation and Commissioning","text":"<p>Prior to the creation of an ADR it is recommended that an Issue is raised in this GitHub repository outlining the need for a new ADR (or update to an existing one). This enables very early discussion around the potential ADR with minimal outlay and effort.</p> <p>Once the proposer wants to move forward with creating/updating an ADR, they are encouraged to use the standard Git/GitHub workflow and raise a Pull Request (PR) ahead of following the decision making process documented here.</p> Example Git Workflow <ul> <li>Clone this repository: <code>git clone git@github.com:GIG-Cymru-NHS-Wales/Architecture-Decision-Records.git</code></li> <li>Create a branch from <code>main</code> to work on (see Naming Conventions):   <code>git checkout main</code>, <code>git checkout -b adr-for-x</code></li> <li>Make the required changes (add/update files) in your editor of choice.   (note the template)</li> <li>Commit the changes: <code>git add changed-file.md</code>, <code>git commit -m \"Added new ADR for x\"</code></li> <li>Push the changes to GitHub <code>git push -u origin HEAD</code></li> <li>Raise a Pull Request on GitHub.com</li> </ul> <p>Notwithstanding the above guidance, the Technical Design Authority (TDA), Technical Design Assurance Group (TDAG), or other relevant governance bodies may commission the creation or update of an ADR in specific areas as needed.</p>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#lifecycle-and-status","title":"Lifecycle and Status","text":"<p>Each ADR progresses through a lifecycle, and its current state is tracked using a defined status. This ensures clarity, traceability, and helps manage the relevance of decisions over time. The <code>Status</code> field in the ADR template must be updated to reflect the current state of the ADR.</p> <p>The defined statuses are:</p> <ul> <li>Proposed: The initial state of an ADR. It has been drafted and is     ready for discussion and review.</li> <li>Under Review: The ADR is actively being discussed and reviewed by     stakeholders (e.g. via a Pull Request for Level 1, or by a Temporary     Decision Group for Level 2+). This status indicates the ADR has moved     past the initial <code>Proposed</code> state and is undergoing evaluation before a     decision is reached.</li> <li>Accepted: The ADR has been approved by the relevant decision-making     process (e.g., consensus on a PR, TDG agreement). The decision     documented is now considered active and should be followed.</li> <li>Rejected: The proposed decision was reviewed but not approved. The ADR     is kept for the record of the discussion and outcome.</li> <li>Superseded: An <code>Accepted</code> ADR that has been replaced by a newer ADR.     The ADR should clearly indicate which ADR supersedes it.</li> <li>Deprecated: An <code>Accepted</code> ADR that is no longer considered relevant or     best practice. It might be phased out or archived but is not directly     replaced by a specific new ADR.</li> </ul> <p>The following diagram illustrates the typical lifecycle flow of an ADR:</p> <pre><code>stateDiagram-v2\n    accTitle: ADR Lifecycle State Diagram\n    accDescr: A diagram showing the various states and transitions for ADRs\n    [*] --&gt; Proposed\n    Proposed --&gt; Under_Review : Submitted for discussion / PR raised\n    Under_Review --&gt; Accepted : Consensus reached / Approved\n    Under_Review --&gt; Rejected : Not approved / Withdrawn\n    Accepted --&gt; Superseded : Replaced by new ADR\n    Accepted --&gt; Deprecated : No longer current best practice\n    Rejected --&gt; [*]\n    Superseded --&gt; [*]\n    Deprecated --&gt; [*]</code></pre>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#quality-and-approval-criteria","title":"Quality and Approval Criteria","text":"<p>For an ADR to be considered \"good enough\" for approval and merging, it should meet a set of quality criteria. These criteria ensure that the decision is well-understood, justified, and provides sufficient context for future reference.</p> <p>The following checklist should be considered during the review of an ADR:</p> <ul> <li>Clear Problem Articulation: Is the problem statement, context, and the   driving factors behind the need for a decision clearly and concisely   described? (See the Summary and Drivers sections in the ADR template)</li> <li>Exploration of Alternatives: Have sufficient and relevant alternative   solutions been considered and documented? (See the Options section.)</li> <li>Documented Rationale and Trade-offs: Is the chosen solution clearly   stated, and is the rationale behind the decision well-justified? Are the   trade-offs (pros, cons, consequences) of the chosen solution and key   alternatives explicitly documented? (See the Options Analysis and   Recommendation sections.)</li> <li>Stakeholder Engagement: Has feedback from relevant stakeholders been   sought and incorporated, or is there a rationale if not?</li> <li>Sufficient Context and Linkages: Does the ADR include necessary   background information, references to related ADRs, issues (e.g., GitHub   issues), or other relevant documentation?</li> <li>Completeness and Clarity: Is the ADR well-written, easy to understand,   and does it adhere to the latest ADR template?</li> </ul> <p>It is the responsibility of the ADR proposer to strive to meet these criteria. During the review process (whether via a Pull Request for Level 1 decisions or within a Temporary Decision Group for higher levels), reviewers and TDG members are expected to assess the ADR against these quality criteria before recommending or granting approval.</p>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#temporary-decision-groups-tdg","title":"Temporary Decision Groups (TDG)","text":"<p>Depending on the level of decision, it may require the formation of a Temporary Decision Group (TDG). This is a group of volunteers that will ideally have relevant expertise/experience in the topic area but also may just have an interest and desire to be involved in the ADR.</p> <p>When a TDG is utilised, any decision reached by the group is automatically accepted by the relevant assurance and governance committee.</p>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#operations-and-decision-making","title":"Operations and Decision Making","text":"<p>Temporary Decision Groups (TDGs) are formed to collaboratively review and decide on ADRs, particularly for Level 2 and above. While open to interested volunteers, ensuring the group possesses the necessary domain expertise is crucial, especially for higher-level decisions (Level 3 and 4). The proposer (for Level 2/3) or the TDA (for Level 4) should actively seek participation from individuals with relevant knowledge and experience when forming the TDG. The governance body commissioning or reviewing the TDG composition is responsible for ensuring adequate expertise is represented.</p> <p>The primary goal of a TDG is to reach consensus on the proposed decision. Consensus means that all members can live with the decision, even if it wasn't their first choice, and support its implementation. Unanimous agreement is ideal but not always required; the aim is to avoid significant unresolved objections.</p> <p>Disagreements are expected and are a valuable part of the process. TDG members should engage in open discussion, present evidence, and explore alternatives to resolve conflicts. If consensus proves difficult to achieve after thorough discussion and exploration, the TDG should document the differing viewpoints and the reasons for the disagreement within the ADR.</p> <p>If a TDG is unable to reach a decision or resolve significant disagreements within the agreed timeframe, the matter should be escalated.</p> <ul> <li>For Level 2 and 3 decisions, the escalation path is back to the     Technical Design Assurance Group (TDAG). The TDG presents the     unresolved issues and differing viewpoints to the TDAG for guidance or     a final decision.</li> <li>For Level 4 decisions, the escalation path is back to the Technical     Design Authority (TDA), which commissioned the TDG.</li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#decision-levels","title":"Decision Levels","text":"<p>To ensure the ADR process is proportionate to the impact and scope of a decision, decisions are categorised into four levels:</p> <p>Note</p> <p>When determining the level, consider also how easily reversible the decision is (can it be easily stopped, omitted, or undone?) and how easily isolatable it is (can it run in parallel with similar decisions without interference?). Decisions that are hard to reverse and/or hard to isolate typically warrant a higher level due to increased risk and commitment.</p>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#level-1-project-specific-decisions","title":"Level 1: Project-Specific Decisions","text":"<ul> <li>Scope: Primarily impacts a single project or a small, closely related   set of components within a project.</li> <li>Impact: Minimal impact outside the immediate project team.</li> <li>Characteristics: Often easily reversible and easily isolatable.   The commitment is typically low, allowing for quick trials and adjustments.</li> <li>Examples: Choice of a specific library within a project, minor   refactoring decisions, specific implementation details that don't affect   external interfaces or broader architectural patterns.</li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#level-2-cross-projectteam-decisions","title":"Level 2: Cross-Project/Team Decisions","text":"<ul> <li>Scope: Impacts multiple projects or teams, but not necessarily the entire   organisation.</li> <li>Impact: Requires coordination or consistency across several teams or   projects.</li> <li>Characteristics: May have varying degrees of reversibility and   isolatability. While potentially more complex to undo or run in parallel   than Level 1, they are generally less entangled than higher-level decisions.</li> <li>Examples: Standardising a specific tool or framework used by several   teams, decisions affecting shared services used by a subset of projects,   changes to internal APIs consumed by multiple teams.</li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#level-3-organisation-wide-decisions","title":"Level 3: Organisation-Wide Decisions","text":"<ul> <li>Scope: Impacts all projects, teams, or the entire organisation's technical   landscape.</li> <li>Impact: Requires broad consensus or mandates organisation-wide   standards or practices.</li> <li>Characteristics: Tend to be harder to reverse due to broad adoption   and significant impact if changed. They may also be harder to isolate   as they often establish organisation-wide standards or affect shared   infrastructure.</li> <li>Examples: Mandated programming languages, standard architectural   patterns for all new services, organisation-wide security policies   affecting technical implementation.</li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#level-4-majorsignificant-decisions","title":"Level 4: Major/Significant Decisions","text":"<ul> <li>Scope: Decisions with significant strategic, technical, or national-   level implications.</li> <li>Impact: High risk, high cost, or significant external visibility/   dependency. May involve external stakeholders or national standards.</li> <li>Characteristics: Typically hard to reverse and hard to isolate,   involving substantial commitment (e.g., financial, training, integration   effort). These demand the most rigorous review and careful consideration.</li> <li>Examples: Adoption of a major new cloud platform, significant changes   to core infrastructure, decisions impacting national data standards or   interoperability.</li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#process-by-level","title":"Process by Level","text":"<p>The process for reviewing and finalising an ADR varies by its defined level:</p>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#level-1-project-specific-decisions-process","title":"Level 1: Project-Specific Decisions Process","text":"<ul> <li>Review Timeframe: A fixed review timeframe (default one week) is set   for the PR by the proposer and specified in the PRs description.</li> <li>Feedback: Team members and other relevant peers provide feedback via the   PR.</li> <li>Approval: The ADR is merged upon reaching consensus or at the end of the   review period if no major objections are raised.</li> <li>Notification: All Level 1 ADRs merged since the last Technical Design   Assurance Group (TDAG) meeting are added as 'below the line' submissions to   the TDAG agenda for information.</li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#level-2-cross-projectteam-decisions-process","title":"Level 2: Cross-Project/Team Decisions Process","text":"<ul> <li>Flagging: The proposer flags the ADR to the Technical Design   Assurance Group (TDAG) agenda as a Level 2 decision.</li> <li>TDG Formation: The proposer explains the ADR at the TDAG and requests   volunteers to form a TDG. The TDG must include at least two reviewers,   in addition to the proposer.</li> <li>Review Timeframe: The proposer, in consultation with the TDG, sets a   timeframe for discussion and review (default: two weeks).</li> <li>Decision: The TDG collaborates on the ADR and collectively makes the   decision.</li> <li>Notification: The finalised ADR and its decision are added to the next   TDAG agenda for information only.</li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#level-3-organisation-wide-decisions-process","title":"Level 3: Organisation-Wide Decisions Process","text":"<p>Level 3 decisions follow the same process as Level 2, but require five members (including the proposer) to form the TDG. In addition to submitting the agreed decision to TDAG for information, it is also submitted to the Technical Design Authority (TDA) agenda (below the line) for information only.</p>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#level-4-majorsignificant-decisions-process","title":"Level 4: Major/Significant Decisions Process","text":"<p>Level 4 decisions follow the same process as Level 3 but the flagging and formation of the TDG is handled directly by TDA, bypassing TDAG, although the outcomes of decisions are shared with TDAG for information.</p>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#roles-and-responsibilities","title":"Roles and Responsibilities","text":"<p>Clear roles and responsibilities are essential for the effective functioning of the ADR process. The following outlines key roles and their involvement:</p>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#stewardship-and-maintenance","title":"Stewardship and Maintenance","text":"<p>The overall \"stewarding\" or \"librarianship\" of the ADRs, including the repository, process documentation, template, and ensuring consistency, falls under the remit of the ADR Steward. This role is expected to be a function within or designated by the Technical Design Assurance Group (TDAG) and/or Technical Design Authority (TDA).</p> <p>Once an ADR is Accepted:</p> <ul> <li>The decision it documents becomes a collective agreement.</li> <li>The ADR Proposer is typically the initial main author.</li> <li>Ongoing maintenance, such as identifying when an ADR might be outdated,     superseded, or deprecated, is a collective responsibility of the     architectural community.</li> <li>The ADR Steward, along with TDAG/TDA, will oversee the health of the     ADR log and may prompt reviews or updates as needed. Proposers of new,     related ADRs should also identify existing ADRs that may need to be     superseded.</li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#key-roles","title":"Key Roles","text":"Role Responsibility ADR Proposer Initiates an ADR, leads its development by drafting content and incorporating feedback. Presents the ADR to the relevant review body (e.g., via Pull Request, or to a TDG/TDAG/TDA). Responsible for ensuring the ADR meets quality criteria. TDG Chair (Often the ADR Proposer, or designated for Level 4 TDGs) Facilitates TDG discussions, ensures fair participation, helps track progress towards a decision, and may assist in summarizing the TDG's outcome and updating the ADR. TDG Members Actively participate in the evaluation, review, and decision-making for Level 2, 3, and 4 ADRs. Contribute expertise, challenge assumptions constructively, and help the TDG reach consensus on the decision. TDAG Facilitates TDG formation for Level 2 &amp; 3 ADRs. Acts as an escalation point for unresolved disagreements in Level 2 &amp; 3 TDGs. Reviews outcomes of Level 1, 2 &amp; 3 ADRs for information and process adherence. Can commission ADRs. Approves requests for private ADRs (Level 2 &amp; 3). Oversees the ADR process and supports the ADR Steward function. TDA Commissions and facilitates TDG formation for Level 4 ADRs. Acts as an escalation point for unresolved disagreements in Level 4 TDGs. Reviews outcomes of Level 3 &amp; 4 ADRs for information. Can commission ADRs. Approves requests for private ADRs (Level 4). Provides ultimate governance oversight for the ADR process and supports the ADR Steward function. ADR Steward (A function likely performed by TDAG/TDA secretariat or a designated individual/team) Owns the ADR repository structure and process documentation. Ensures ADR template compliance, consistency across ADRs, and manages the lifecycle metadata (e.g., status updates in the log). Assists in reporting on ADR activity."},{"location":"design-authority/dhcw/architecture-decision-record-process/#stages-activities-and-owners","title":"Stages, Activities and Owners","text":"Stage Activities Owner(s) 1. Pre-ADR Discussion Raise a GitHub Issue describing the problem or opportunity. ADR Proposer 2. Drafting the ADR Use template, outline problem, context, options. ADR Proposer 3. Assigning a Decision Level Determine decision level (1-4) based on scope/impact. ADR Proposer (reviewed by ADR Steward or TDAG) 4. Pull Request Creation Submit ADR draft as PR in the GitHub repo. ADR Proposer 5. TDG Formation (if Level \u22652) Identify and confirm volunteers, define TDG scope. ADR Proposer, with TDAG or TDA for Level 3/4 6. Review &amp; Collaboration Drive reviews, manage discussion, gather feedback. TDG Chair (or Proposer for Level 1) 7. Decision Making Reach consensus, capture rationale, finalise ADR. TDG (Chair facilitates), ADR Proposer 8. Approval &amp; Merge Merge PR, assign status (e.g. Approved), label by level ADR Proposer 9. Communication Add to TDAG/TDA agenda as needed, broadcast key decisions. TDAG &amp; TDA Coordinators 10. Lifecycle Management Monitor for relevance, deprecate outdated ADRs. ADR Steward"},{"location":"design-authority/dhcw/architecture-decision-record-process/#approval-authority","title":"Approval Authority","text":"<p>The primary role of TDAG and TDA in the context of ADRs that have been through a Temporary Decision Group (TDG) is one of oversight, process assurance, and handling escalations, rather than a direct re-approval or veto of a TDG's consensus decision.</p> <p>As stated in the \"Temporary Decision Groups (TDG)\" section, \"When a TDG is utilised, any decision reached by the group is automatically accepted by the relevant assurance and governance committee.\"</p> <p>TDAG/TDA members participate in TDGs relevant to their expertise, contributing to the consensus directly within that forum. Their \"approval\" authority is exercised through:</p> <ul> <li>Commissioning ADRs.</li> <li>Defining the scope and level of ADRs.</li> <li>Facilitating and ensuring the proper constitution of TDGs (especially         for Level 3 and 4).</li> <li>Acting as the escalation point if a TDG cannot reach consensus.</li> <li>Governing the overall ADR process itself.</li> <li>Approving exceptions, such as the private ADR process.</li> <li>For Level 1 ADRs (which do not use a TDG), the approval is by peer     consensus on the Pull Request, with TDAG reviewing for information.</li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#compliance-enforcement","title":"Compliance &amp; Enforcement","text":"<p>Beyond the ADR approval process, TDA and TDAG also play a key role in upholding the decisions documented in <code>Accepted</code> ADRs. Architectural designs and proposals submitted to TDA/TDAG for review are expected to align with these decisions.</p> <p>The ADR template includes a <code>Confirmation</code> section for proposers to articulate this alignment, justify any deviations, and to propose specific methods for confirming ongoing compliance with the decision.</p> <p>TDA and TDAG have the authority to challenge or reject submissions that do not adequately comply with, or justify deviations from, <code>Accepted</code> ADRs, thereby ensuring architectural consistency and adherence to accepted decisions.</p> <p>Teams need to be proactive in consulting the ADRs and using them as a living knowledge base of architectural decisions to inform designs and approaches.</p>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#handling-sensitive-or-secure-adrs","title":"Handling Sensitive or Secure ADRs","text":"<p>The default is to collaborate on ADRs via the DHCW public GitHub repository, in the open.</p> <p>While ADRs are public by default to promote transparency, there are exceptional circumstances where the subject matter is highly sensitive (e.g., involving security vulnerabilities, confidential commercial information, or critical infrastructure details that should not be broadly disclosed).</p>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#requesting-a-private-adr-process","title":"Requesting a Private ADR Process","text":"<p>If a proposed ADR topic is believed to be highly sensitive:</p> <ol> <li>The proposer must formally request an exception for private discussion     and restricted documentation from the Technical Design Authority (TDA)     or the Technical Design Assurance Group (TDAG) (depending on the     level of decision). This request should be made through appropriate internal     channels and should outline the nature of the sensitivity and why a private     process is necessary.</li> <li>The TDA/TDAG will review the request. Approval for a private process will     be granted if the justification for sensitivity is deemed valid.</li> </ol>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#private-discussion-and-documentation","title":"Private Discussion and Documentation","text":"<p>If approved for a private process:</p> <ul> <li>Discussions will occur in a restricted forum, as determined and facilitated     by the TDA/TDAG (e.g., a private channel, dedicated secure meetings).</li> <li>An ADR will still be created using the standard template and will follow the     standard lifecycle (e.g., Proposed, Accepted).</li> <li>However, the ADR itself, containing sensitive details, will be stored in a     secure, access-controlled location designated by the TDA/TDAG, rather     than the public repository.</li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#transparency-of-outcome-for-private-adrs","title":"Transparency of Outcome for Private ADRs","text":"<p>To maintain a degree of transparency and traceability while protecting sensitive information a placeholder or summary ADR may be created in the public repository.</p> <p>This public-facing ADR would typically:</p> <ul> <li>Indicate that a decision on a sensitive topic has been made and recorded.</li> <li>State the ADR title (if the title itself is not sensitive).</li> <li>Provide a high-level, non-sensitive summary of the decision's scope or     impact, if possible and appropriate.</li> <li>Clearly state that the full details are restricted and stored in a     secure location due to sensitivity, referencing the approval from     TDA/TDAG.</li> <li>Link to the original generic public issue if one was created.</li> <li>The decision on whether to create a public placeholder/summary, and the     level of detail it contains, will be made by the TDA/TDAG, in     consultation with relevant security and information governance stakeholders.</li> <li>The existence of the decision and its status (e.g., Accepted) should still     be traceable through appropriate governance channels (TDA/TDAG records),     even if the full content is not publicly accessible.</li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#general-approach","title":"General Approach","text":"<p>The TDG (or the original proposer, for less complex ADRs) will conduct thorough research, analysis, and evaluation of potential solutions or options. This may involve:</p> <ul> <li>Gathering additional information and requirements.</li> <li>Evaluating different architectural patterns or technologies.</li> <li>Assessing the potential risks and benefits of each option.</li> <li>Developing prototypes or proof-of-concepts, if necessary.</li> </ul> <p>Throughout the development process, the TDG (or proposer) should actively seek feedback from relevant stakeholders, including other architects, developers, operations engineers, and business representatives. This feedback should be incorporated into the ADR document.</p>"},{"location":"design-authority/dhcw/architecture-decision-record-process/#appendix-adr-creation-workflow","title":"Appendix - ADR Creation Workflow","text":"<p>The following diagram illustrates the typical end-to-end process for creating and approving an ADR, from initial idea to a recorded decision.</p> <pre><code>graph TD\n    accTitle: ADR Workflow\n    accDescr: Flowchart showing the typical steps for proposing, developing, and deciding on an Architecture Decision Record.\n\n    Start([\"Start: Identify need for a new or updated ADR\"]) --&gt; Raise_GitHub_Issue(\"Optional: Raise GitHub Issue for Early Discussion\");\n    Raise_GitHub_Issue          --&gt; Is_Sensitive{\"Is ADR content expected to be **sensitive**?\"};\n\n    %% Private or Public ADR\n    Is_Sensitive        -- Yes  --&gt; Request_Private[\"Request private process from TDAG (Level 1-3) or TDA (Level 4)\"];\n    Is_Sensitive        -- No   --&gt; Process_Publicly;\n\n    Request_Private             --&gt; Private_Approval{\"Private Process Approved?\"};\n    Private_Approval    -- Yes  --&gt; Process_Privately[\"ADR Handled **Privately**: Secure discussion &amp; storage. **Optional** public placeholder on GitHub.\"];\n    Private_Approval    -- No   --&gt; Process_Publicly[\"ADR Handled **Publicly**: Open discussion, public storage via GitHub &amp; Pull Request process\"];\n    Process_Privately           --&gt; TDG_Decision{\"Decision Level?\"};\n    Process_Publicly            --&gt; TDG_Decision;\n\n    %% Level 1 Process\n    TDG_Decision        -- 'Level 1'    --&gt; Peer_Review_ADR[\"Proposer requests ADR Peer Review (default: 1 week)\"];\n    Peer_Review_ADR     --&gt; TDG_Consensus_Q\n\n    %% Level 2 - 4 Process\n    TDG_Decision        -- 'Level &gt;= 2' --&gt; Flag_TDAG_TDA[\"Flag to TDAG (Level 2 &amp; 3) or TDA (Level 4)\"];\n\n    Flag_TDAG_TDA --&gt; TDG_Formed[\"TDG Formed (Proposer + members, size / composition varies by level)\"];\n\n    TDG_Formed --&gt; TDG_Collaboration[\"TDG Collaborates, Reviews &amp; Seeks Consensus (default: 2 weeks)\"];\n\n    TDG_Collaboration --&gt; TDG_Consensus_Q{\"General Consensus on ADR?\"};\n    TDG_Consensus_Q -- Yes --&gt; Accept_Reject_ADR;\n    TDG_Consensus_Q -- No --&gt; Escalate[\"Escalate to TDAG (Level 1 - 3) or TDA (Level 4) for Resolution\"];\n    Escalate --&gt; TDAG_TDA_Decides[\"TDAG/TDA Makes Final Decision\"];\n    TDAG_TDA_Decides --&gt; Accept_Reject_ADR;\n\n    %% Finalise ADR\n    Accept_Reject_ADR[\"Update ADR Status (e.g., 'Accepted', 'Rejected') &amp; Merge Pull Request\"] --&gt; Notify_Governance[\"Notify TDAG (Level 1-3) and TDA (Level 4)\"];\n    Notify_Governance --&gt; End([\"End\"]);</code></pre>"},{"location":"design-authority/dhcw/architecture-decision-records-naming-conventions/","title":"Architecture Decision Records Naming Convention","text":"<p>Pending Approval</p> <p>Awaiting approval by DHCW Technical Design Authority</p> <p>Status: proposed Date: 2025-03-25 Governance: Drafted for DHCW Technical Design Authority (TDA) for approval</p>"},{"location":"design-authority/dhcw/architecture-decision-records-naming-conventions/#situation-context-and-problem-statement","title":"Situation - Context and Problem Statement","text":"<ul> <li>We want to record architecture related decisions for NHS Wales organisations, made via agreed governance mechanisms.</li> <li>We need to agree a naming convention for the records i.e how to name records and refer to them.</li> <li>We should also agree a folder &amp; filename convention aligned with the naming convention.</li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-records-naming-conventions/#background-decision-drivers","title":"Background - Decision Drivers","text":"<p>We want:</p> <ul> <li>a consistent naming convention for our decisions.</li> <li>names to be human readable and easy to understand.</li> <li>to be able to cross-reference Architecture Decision Records easily.</li> <li>the naming to support multiple Architecture Decision Records being developed in parallel (i.e. avoid naming clashes).</li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-records-naming-conventions/#assessment-considered-options","title":"Assessment - Considered Options","text":"<p>For naming itself:</p> <ul> <li>Just sequential numbering e.g. ADR 0001, ADR 0002, ...</li> <li>Sequential numbering and titles e.g. ADR 0001 - Title, ADR 0002 - Title, ...</li> <li>Just titles e.g. \"Title of a Record\"</li> <li>Formless \u2013 No naming convention - author's choice.</li> </ul> <p>For filenames:</p> <ul> <li>The title of the Architecture Decision Record as above as-is e.g. <code>Title Goes Here.md</code></li> <li>Use of lowercase 'kebab' style for filenames e.g. <code>title-goes-here.md</code></li> <li>Use of lowercase 'snake' style for filenames e.g. <code>title_goes_here.md</code></li> </ul> <p>On acronyms:</p> <ul> <li>Use 'ADR' as an acronym for Architecture Decision Record.</li> <li>Avoid acronyms, e.g. always spell out \"Architecture Decision Record\" in full.</li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-records-naming-conventions/#recommendation-decision-outcome","title":"Recommendation - Decision Outcome","text":""},{"location":"design-authority/dhcw/architecture-decision-records-naming-conventions/#naming-conventions","title":"Naming Conventions","text":"<p>Adopt an Architecture Decision Record naming convention of:</p> <ul> <li>Just titles, in Title Case</li> <li>Author to ensure the title makes it clear what the decision relates to.</li> <li>Author to ensure titles are human readable and unique.</li> <li>Avoid the use of acronyms</li> <li>Examples:</li> <li>'Use Architecture Decision Records and Structure'</li> <li>'Architecture Decision Records Naming Conventions'</li> <li>'Format Architecture Decision Records with Markdown'</li> </ul> <p>Whilst numbering Architecture Decision Records makes them easy to cross-reference, it introduces an administrative/process overhead to ensure numbers are unique and sequential and adds complexity in the ordering of records, especially when multiple records are in development in parallel (which gets published first, who gets the next record number etc.)</p> <p>Avoiding acronyms and using human readable names makes them easier for users to understand, refer to and talk about.</p> <p>Note: We are referring to 'Architecture' decision records, not 'Architectural' or other similar words.</p> <p>Note: Readability is important, it may be better to refer to Architecture Decision Records as decisions and records in documents rather than always writing out the full Architecture Decision Records every time e.g.</p> <ul> <li>\"This record builds on the previous decision\" (good - emphasis only added here for clarity).</li> <li>\"This Architecture Decision Record builds on the previous Architecture Decision Record\" (worse/avoid).</li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-records-naming-conventions/#folder-and-filenames","title":"Folder and Filenames","text":"<p>Given the above, apply the following convention to the storage and naming of records, this convention makes publishing easier even though it adds a little complexity:</p> <p>Each decision should have its own folder, whose name should match the Title of the record, with whitespace removed and adopting a kebab style e.g.</p> <ul> <li><code>./architecture-decision-records-naming-conventions/</code></li> <li><code>./use-architecture-decision-records-and-structure/</code></li> <li><code>./format-architecture-decision-records-with-markdown/</code></li> </ul> <p>Within each folder create an <code>index.md</code> file which contains the decision contents. Create a symbolic link from <code>README.md</code> to <code>index.md</code> - this ensures that GitHub renders the documents when navigating the repository e.g.</p> <ul> <li><code>./architecture-decision-records-naming-conventions/index.md</code></li> <li><code>./architecture-decision-records-naming-conventions/README.md -&gt; index.md</code></li> </ul> <p>Both <code>index.md</code> and <code>README.md</code> should be added and committed to Git.</p> Creating a symbolic link (Windows/Mac/Linux) WindowsMacOS/Linux <p>You can think of a symbolic link as a shortcut that points to another file.</p> <p>Note PowerShell doesn't seem to create relative symbolic links so you must instead launch Command Prompt with Admin privileges, navigate to the folder containing the index.md and run:</p> <p><code>mklink README.md index.md</code></p> <p>Running <code>dir</code> afterwards should show output similar to this:</p> <pre><code>    &gt; dir\n     ...\n    16/05/2025  13:04    &lt;DIR&gt;          .\n    16/05/2025  13:01    &lt;DIR&gt;          ..\n    16/05/2025  13:01             5,660 index.md\n    16/05/2025  13:04    &lt;SYMLINK&gt;      README.md [index.md]\n</code></pre> <p>Navigate to the folder containing the index.md and run:</p> <p><code>ln -s index.md README.md</code></p>"},{"location":"design-authority/dhcw/architecture-decision-records-naming-conventions/#cross-referencing","title":"Cross Referencing","text":"<p>When cross-referencing decisions, use the full title of the decision and add a relative link to the record <code>index.md</code> itself e.g.</p> <ul> <li>See Architecture Decision Records Naming Conventions</li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-records-naming-conventions/#branches","title":"Branches","text":"<p>Git branch names should utilise the same convention as the main folder name of the decision itself e.g.</p> <ul> <li><code>git checkout -b architecture-decision-records-naming-conventions</code></li> </ul>"},{"location":"design-authority/dhcw/architecture-decision-records-naming-conventions/#confirmation","title":"Confirmation","text":"<p>This decision will be enforced by reviewers of newly submitted records, who should refer to this decision and confirm the naming convention and decision herein is being adhered to.</p>"},{"location":"design-authority/dhcw/architecture-decision-records-naming-conventions/#more-information","title":"More Information","text":"<p>See Use Architecture Decision Records and Structure for the structure of records.</p>"},{"location":"design-authority/dhcw/format-architecture-decision-records-with-markdown/","title":"Format Architecture Decision Records using plaintext Markdown","text":"<p>Pending Approval</p> <p>Awaiting approval by DHCW Technical Design Authority</p> <p>Status: proposed Date: 2025-03-27 Governance: Drafted for DHCW Technical Design Authority (TDA) for approval</p>"},{"location":"design-authority/dhcw/format-architecture-decision-records-with-markdown/#situation-context-and-problem-statement","title":"Situation - Context and Problem Statement","text":"<ul> <li>We want to record architecture related decisions for NHS Wales organisations, made via agreed governance mechanisms.</li> <li>The structure is decided by Use Architecture Decision Records</li> <li>We need to agree the format.</li> </ul>"},{"location":"design-authority/dhcw/format-architecture-decision-records-with-markdown/#background-decision-drivers","title":"Background - Decision Drivers","text":"<ul> <li>We want the format to be simple and easy to publish on the internet.</li> <li>We want the format to support 'formatting' e.g. headings, bold, italics, lists.</li> <li>We don't want any proprietary tools to be required to contribute Architecture Decision Records.</li> <li>We want to align with industry standards (not reinvent the wheel).</li> <li>We want the selected format to be easily adopted.</li> </ul>"},{"location":"design-authority/dhcw/format-architecture-decision-records-with-markdown/#assessment-considered-options","title":"Assessment - Considered Options","text":"<ul> <li>Markdown</li> <li>Microsoft DOCX</li> <li>Open Document</li> <li>No format \u2013 just plaintext</li> </ul>"},{"location":"design-authority/dhcw/format-architecture-decision-records-with-markdown/#recommendation-decision-outcome","title":"Recommendation - Decision Outcome","text":"<p>Format Architecture Decision Records as plaintext Markdown documents, using the CommonMark specification.</p> <ul> <li>Allows for Architecture Decision Records to be created and edited in any text editor, no specific software needed.</li> <li>Markdown is easy to learn.</li> <li>Markdown supports the basic formatting we need (bold, italics, headings, lists etc.)</li> <li>Due to the limitations, it guides us to keep things simple (KISS) and easy to read.</li> <li>The CommonMark standard for Markdown is supported by GitHub and many other tools, so widely supported.</li> </ul> <p>Tip</p> <p>Use Markdown Lint in Visual Studio  Code to ensure the formatting in documents will work well when publishing/rendering.</p>"},{"location":"design-authority/dhcw/format-architecture-decision-records-with-markdown/#consequences","title":"Consequences","text":"<ul> <li>This does require some learning as most staff are familiar with DOCX/Word and may have limited experience of Markdown.</li> <li>Markdown limits the formatting of the document (can be seen as a positive) so users may be constrained in presenting information.</li> </ul>"},{"location":"design-authority/dhcw/format-architecture-decision-records-with-markdown/#more-information","title":"More Information","text":"<p>See Use Architecture Decision Records and Structure for the structure of an Architecture Decision Record.</p>"},{"location":"design-authority/dhcw/use-architecture-decision-records-and-structure/","title":"Use Architecture Decision Records and Structure","text":"<p>Pending Approval</p> <p>Awaiting approval by DHCW Technical Design Authority</p> <p>Status: proposed Date: 2025-03-25 Governance: Drafted for DHCW Technical Design Authority (TDA) for approval</p>"},{"location":"design-authority/dhcw/use-architecture-decision-records-and-structure/#situation-context-and-problem-statement","title":"Situation - Context and Problem Statement","text":"<ul> <li>We want to record architecture related decisions for NHS Wales organisations, made via agreed governance mechanisms.</li> <li>We need to agree the structure of the records i.e what information a record should contain.</li> </ul>"},{"location":"design-authority/dhcw/use-architecture-decision-records-and-structure/#background-decision-drivers","title":"Background - Decision Drivers","text":"<ul> <li>We want the structure to support both detailed and lightweight records.</li> <li>We want to align with industry standards (not reinvent the wheel).</li> <li>We want the selected structure to be easily adopted.</li> </ul>"},{"location":"design-authority/dhcw/use-architecture-decision-records-and-structure/#assessment-considered-options","title":"Assessment - Considered Options","text":"<p>The structure utilised by:</p> <ul> <li>Michael Nygard's template \u2013 The first incarnation of the term \"Architecture Decision Records\" (ADR)</li> <li>MADR 4.0.0 \u2013 The Markdown Architectural Decision Records</li> <li>Decision record template by Jeff Tyree and Art Akerman - Used in CapitalOne (regulated industry)</li> <li>Other templates listed at https://github.com/joelparkerhenderson/architecture_decision_record</li> <li>SBAR (Situation, Background, Assessment, Recommendation) template - used by DHCW internally and in healthcare generally.</li> <li>Formless \u2013 No conventions for structure</li> </ul>"},{"location":"design-authority/dhcw/use-architecture-decision-records-and-structure/#recommendation-decision-outcome","title":"Recommendation - Decision Outcome","text":"<p>Adopt an Architecture Decision Record structure with mandatory and optional fields,  taking elements of MADR and aligning it with the existing SBAR structure.</p> <ul> <li>Allows for structured capturing of any decision.</li> <li>The structure is comprehensible and facilitates usage &amp; maintenance.</li> <li>It allows varying levels of detail to suit the decision being made.</li> <li>Aligns with existing terminology and structure that teams will be familiar with.  </li> <li>The structure enables flexibility in format, storage and publishing.</li> </ul> <p>See Architecture Decision Record Template</p>"},{"location":"design-authority/dhcw/use-material-for-mkdocs-for-publishing/","title":"Use Material for MkDocs for Publishing","text":"<p>Pending Approval</p> <p>Awaiting approval by DHCW Technical Design Authority</p> <p>Status: proposed Date: 31/03/2025 Governance: Drafted for DHCW Technical Design Authority (TDA) for approval</p>"},{"location":"design-authority/dhcw/use-material-for-mkdocs-for-publishing/#situation-context-and-problem-statement","title":"Situation - Context and Problem Statement","text":"<p>We are capturing architecture decisions as plaintext Markdown documents and storing these in a GitHub repository. This is quite a 'technical' way of working that requires understanding of Git, Markdown and the GitHub.com website and workflow. This represents a barrier for people engaging with our content.</p>"},{"location":"design-authority/dhcw/use-material-for-mkdocs-for-publishing/#background-decision-drivers","title":"Background - Decision Drivers","text":"<p>We want:</p> <ul> <li>to use our existing Markdown files, not create separate documents</li> <li>the content to be open and public (no login, paywall, registration etc.)</li> <li>the content to be kept up-to-date automatically</li> <li>a good user experience and visual design</li> <li>alignment with NHS Wales branding</li> <li>the ability for user to search our content</li> <li>the ability for users to navigate our content in a logical and structured way</li> <li>a widely supported approach/technology</li> <li>a free and open source solution</li> <li>low or no cost</li> <li>something easy to configure/manage and work with</li> <li>flexibility to change in the future should we choose</li> </ul>"},{"location":"design-authority/dhcw/use-material-for-mkdocs-for-publishing/#assessment-considered-options","title":"Assessment - Considered Options","text":"<ul> <li>GitHub Pages with Jekyll</li> <li>Docusaurus</li> <li>Readthedocs</li> <li>MkDocs</li> <li>Material for MkDocs</li> <li>A review of these alternative tools</li> </ul>"},{"location":"design-authority/dhcw/use-material-for-mkdocs-for-publishing/#recommendation-decision-outcome","title":"Recommendation - Decision Outcome","text":"<p>Use Material for MkDocs hosted on  GitHub Pages.</p> <p>Rationale:</p> <ul> <li>MkDocs allows us to build static HTML files from Markdown files, these can be published using GitHub Pages, at no cost.</li> <li>MkDocs is FOSS; mature, well supported and actively maintained.</li> <li>It is simple to setup and run locally.</li> <li>It is based on Python, which is destined to be one of our preferred languages.</li> <li>It is straightforward to automate publishing using GitHub Actions, meaning the site is always up-to-date with the latest changes.</li> <li>The 'Material' theme provides a good user experience that is visually pleasing</li> <li>Plugins and Markdown extensions provide us flexibility to enhance the site in future.</li> <li>The default site/layout/organisation fits our needs/audience well.</li> <li>It is is commitment, we could change to another of the solutions with minimal effort in the future.</li> </ul> <p>Other options ruled out:</p> <ul> <li>Docusaurus - preference was for a static HTML site rather than a Single Page App/Javascript heavy approach, keeping things simple.</li> <li>readthedocs - Was a strong contender, and it does have a free plan, but this has advertising embedded and an on-ramp to paid plans which we prefer to avoid</li> <li>Jekyll/GitHub Pages - The default site/layout/organisation wasn't as favourable as Material for MkDocs.</li> </ul>"},{"location":"design-authority/ea-metamodel/","title":"Introduction","text":"<p>Our Enterprise Architecture Metamodel provides a structured overview of the core component types and their relationships within our model.</p> <p>We are utilising a single shared instance of Ardoq to model the health and care architecture across NHS Wales.</p> <p>Our metamodel is derived from the Ardoq Use Case Solutions and customised the fit the context of NHS Wales. Any deviations from the Ardoq recommended metamodel are capture as metamodel decisions.</p>"},{"location":"design-authority/ea-metamodel/#decisions","title":"Decisions","text":"<p>Warning</p> <p>If a new decision/change is made to the metamodel ensure the metamodel diagram here is updated alongside the Gremlin query and associated report in Ardoq</p> <p>The following decisions have been made regarding the metamodel:</p> <ul> <li>Multiple Application Instances</li> </ul>"},{"location":"design-authority/ea-metamodel/#metamodel-diagram","title":"Metamodel Diagram","text":"<p>This is a high-level diagram of the metamodel to aid comprehension, it is a non-exhaustive view and therefore  doesn't capture every aspect of the model.</p> <pre><code>graph TD\n  accTitle: Enterprise Architecture Metamodel.\n  accDescr: A diagram showing a high level relationships between components in the enterprise architecture metamodel.\n  Business_Capability --&gt;|Is Realized By| Application\n  Technical_Capability --&gt;|Is Realized By| Application\n  Person --&gt;|Belongs To| Organization\n  Person --&gt;|Assigned To| Roles\n  Person --&gt;|Owns, Is Expert In| Application\n  Organisation --&gt;|Own, Supports, Supplies, Consumes| Application\n  External_Organisation --&gt;|Supplies| Application\n  Application --&gt;|Is Supported By| Database\n  Application --&gt;|Accesses / Connects To| Logical_Information\n  Application --&gt;|Connects To / Is Supported By / Depends On| Technology_Service\n  Infrastructure --&gt;|Is Supported By| Database\n  Database --&gt;|Is Located At| Locations\n  Technology_Services --&gt;|Is Supported By| Infrastructure</code></pre> <p>Tip</p> <p>See Mermaid Docs for more information on creating/editing these diagrams and the Mermaid Live Editor.</p>"},{"location":"design-authority/ea-metamodel/#metamodel-compliance-query","title":"Metamodel Compliance Query","text":"<p>A Gremlin query is maintained within Ardoq to produce a \"Metamodel Compliance\" report. It will identify any relationships between components that do not match the agreed metamodel (i.e. non-compliant 'source -&gt; reference -&gt; target' relationships).</p> <p>The source for this query is maintained within the <code>ea-metamodel-compliance.groovy</code> file of this repository, allowing for version control. The contents of the latest version of this query can be seen below:</p> ea-metamodel-compliance.groovy<pre><code>def validReferences = [\n  ['Business Capability', 'Is Realized By', 'Application'],\n  ['Business Capability', 'ardoq_parent', 'Business Capability'],\n  ['Technical Capability', 'Is Realized By', 'Application'],\n  ['Technical Capability', 'ardoq_parent', 'Technical Capability'],\n  //\n  ['Person', 'Is Expert In', 'Application'],\n  ['Person', 'Is Expert In', 'Business Capability'],\n  ['Person', 'Owns', 'Application'],\n  //\n  ['Organizational Unit', 'Consumes', 'Application'],\n  ['Organizational Unit', 'Consumes', 'Application Module'],\n  ['Organizational Unit', 'Supplies', 'Application'],\n  ['Organizational Unit', 'Supports', 'Application'],\n  ['Organizational Unit', 'Owns', 'Application'],\n  ['Organizational Unit', 'ardoq_parent', 'Organization'],\n  ['Organizational Unit', 'ardoq_parent', 'Organizational Unit'],\n  ['Organizational Unit', 'Partners With', 'Organizational Unit'],\n  //\n  ['Application Module', 'ardoq_parent', 'Application'],\n  ['Application', 'ardoq_parent', 'Application'],\n  ['Application', 'ardoq_parent', 'Application Group'],\n  ['Application', 'Has Successor', 'Application'],\n  ['Application', 'Connects To', 'Application'],\n  ['Application', 'Depends On', 'Application'],\n  ['Interface', 'ardoq_parent', 'Application'],\n  ['Interface', 'Connects To', 'Application']\n]\n\ndef isLegalReference = {\n  project('sourceType', 'type', 'targetType').\n    by(outV().label()).\n    by(label()).\n    by(inV().label()).\n  filter{\n    validReferences.any{ validReference -&gt;\n      validReference[0] == it.get()['sourceType'] &amp;&amp;\n      validReference[1] == it.get()['type'] &amp;&amp;\n      validReference[2] == it.get()['targetType']\n    }\n  }\n}\n\ng.V().\n  hasLabel('Application', 'Business Capability', 'Person', 'Organizational Unit').\n  bothE().\n  dedup().\n  not(isLegalReference()).\n  project('source', 'source type', 'reference', 'target', 'targetType type').\n    by(outV().values('name')).\n    by(outV().label()).\n    by(label()).\n    by(inV().values('name')).\n    by(inV().label())\n</code></pre>"},{"location":"design-authority/ea-metamodel/multiple-application-instances/","title":"Multiple Application Instances","text":"<p>Success</p> <p>Decision Made: 09/05/2025</p>"},{"location":"design-authority/ea-metamodel/multiple-application-instances/#decision-required","title":"Decision Required","text":"<p>How to represent multiple instances of an Application.</p>"},{"location":"design-authority/ea-metamodel/multiple-application-instances/#description","title":"Description","text":"<p>Where a Application has a separate instances for different consumers (e.g. each Health Board has its own instance of an Application ~ such as WelshPAS) we need a way to represent this.</p>"},{"location":"design-authority/ea-metamodel/multiple-application-instances/#decision","title":"Decision","text":"<p>There will be a 'generic' representation of the Application in the metamodel and each 'instance' of the Application will be represented as children with a descriptive identified added to the name e.g.</p>"},{"location":"design-authority/ea-metamodel/multiple-application-instances/#rationale","title":"Rationale","text":"<p>Whilst this adds complexity to the model and will lead to duplication it better represents the reality of the enterprise and the inherent complexity. In addition, it allows relationships that are specific to a particular instance to be modelled.</p>"},{"location":"design-authority/ea-metamodel/multiple-application-instances/#model-diagram","title":"Model Diagram","text":"<pre><code>graph TD\n  accTitle: Example WelshPAS Instances Model\n  accDescr: Shows an example of the parent/child relationship for WelshPAS where each Health Board has its own instance of the application.\n  WelshPAS --&gt; W1[\"WelshPAS [ABUHB]\"]\n  WelshPAS --&gt; W2[\"WelshPAS [BCUHB]\"]\n  WelshPAS --&gt; W3[\"WelshPAS [CTM]\"]\n  WelshPAS --&gt; W4[\"WelshPAS [...]\"]</code></pre>"},{"location":"design-authority/principles/","title":"Introduction","text":"<p>The following principles have been approved by the DHCW Technical Design Authority (TDA):</p> <ul> <li>Architecture Principles</li> <li>Open Architecture &amp; Integration</li> <li>Digital Workplace</li> <li>Data &amp; Analytics</li> <li>Cloud &amp; Infrastructure</li> <li>Security &amp; Identity</li> </ul> <p>The following principles are under development:</p> <ul> <li>User-Centred Design Principles</li> <li>Digital Products &amp; Software Engineering</li> <li>Clinical Principles</li> </ul>"},{"location":"design-authority/principles/architecture-principles/","title":"Architecture Principles","text":"<p>Warning</p> <p>Proposed changes to these principles are under review by the DHCW TDA</p>"},{"location":"design-authority/principles/architecture-principles/#deliver-sustainable-services","title":"Deliver sustainable services","text":"<p>All digital services need to be delivered sustainably.</p>"},{"location":"design-authority/principles/architecture-principles/#put-our-tools-in-modern-browsers","title":"Put our Tools in Modern Browsers","text":"<p>All digital services should be browser based and utilise open web standards.</p>"},{"location":"design-authority/principles/architecture-principles/#internet-first","title":"Internet first","text":"<p>All digital services should adopt internet standards and protocols including setting the default that services are available over the public internet.</p>"},{"location":"design-authority/principles/architecture-principles/#public-cloud-first","title":"Public Cloud first","text":"<p>Digital services should move to the public cloud unless there is a clear reason not to do so.</p>"},{"location":"design-authority/principles/architecture-principles/#build-a-data-layer-with-registers-and-apis","title":"Build a data layer with registers and APIs","text":"<p>Digital services should only store data once (usually where collected) and make it available via open APIs whilst maintaining privacy and security.</p>"},{"location":"design-authority/principles/architecture-principles/#adopt-appropriate-cyber-security-standards","title":"Adopt appropriate cyber security standards","text":"<p>Services must adopt the appropriate cyber security standards subject to risk appetite, including keeping all software, networks and systems up to date.</p>"},{"location":"design-authority/principles/architecture-principles/#use-platforms","title":"Use Platforms","text":"<p>Digital services should build upon existing platforms to deliver their services.</p>"},{"location":"design-authority/principles/architecture-principles/#ask-what-the-user-need-is","title":"Ask what the user need is","text":"<p>Every service must be designed around user needs, whether the needs of the public, clinicians or other staff.</p>"},{"location":"design-authority/principles/architecture-principles/#interoperability-with-open-data-and-technology-standards","title":"Interoperability with open data and technology standards","text":"<p>Digital services should adopt open data and technology standards.</p>"},{"location":"design-authority/principles/architecture-principles/#reuse-before-buy-build","title":"Reuse before buy / build","text":"<p>Digital services should demonstrate that they have sought to reuse existing solutions before delivering new ones. Where is it not possible to reuse an existing solution, off the-shelf (commercial or open source) products should be considered. For open-source products there should be an appropriate level of contractual support provided. Only having ruled out the former two options should a new solution be built, either in-house or through third parties</p>"},{"location":"design-authority/principles/cloud-and-infrastructure/","title":"Cloud and Infrastructure Principles","text":"<p>Approved</p> <p>These principles have been approved by the DHCW TDA</p>"},{"location":"design-authority/principles/cloud-and-infrastructure/#multi-cloud","title":"Multi Cloud","text":"<p>For SaaS solutions and specialist PaaS services, we will choose our provider based on analysis of capabilities in the marketplace. For IaaS and generic PaaS deployments we will identify a single provider of these services.</p>"},{"location":"design-authority/principles/cloud-and-infrastructure/#make-security-easy-to-adopt","title":"Make security easy to adopt","text":"<p>Common security tooling and monitoring to be implemented for all clouds. We will build the underpinning cloud security infrastructure and monitoring systems, so that these are available for everyone to use. Technical solutions (guardrails/policies) will be implemented to reduce risk of user error when configuring cloud services.</p>"},{"location":"design-authority/principles/cloud-and-infrastructure/#design-for-portability","title":"Design for portability","text":"<p>Design for portability and avoid vendor lock-in unless there is compelling case for doing so.</p>"},{"location":"design-authority/principles/cloud-and-infrastructure/#design-for-self-service","title":"Design for self-service","text":"<p>Leverage automation for infrastructure deployment, configuration management, and testing. Utilise Infrastructure as Code (IaC) practices and continuous integration/continuous deployment (CI/CD) pipelines. Self-service should be adopted where possible.</p>"},{"location":"design-authority/principles/cloud-and-infrastructure/#keep-the-network-simple-resilient-and-reliable","title":"Keep the network simple, resilient and reliable","text":"<p>The network systems should be kept as simple as possible with a focus on reliability and availability, even during periods of planned maintenance.</p>"},{"location":"design-authority/principles/cloud-and-infrastructure/#optimise-cloud-benefits","title":"Optimise cloud benefits","text":"<p>Maximise the benefits of using the cloud. Utilise the cloud services that deliver most value to the organisation. Select the most optimum service model (SaaS, FaaS, PaaS, IaaS, etc). Offload management overhead where possible.</p>"},{"location":"design-authority/principles/cloud-and-infrastructure/#design-for-elasticity-and-cost-optimisation","title":"Design for elasticity and cost optimisation","text":"<p>Design for efficiency and cost minimisation \u2013 lever the elasticity of cloud services.</p>"},{"location":"design-authority/principles/cloud-and-infrastructure/#design-for-reliability","title":"Design for reliability","text":"<p>Design for high-availability, resilience, data protection and disaster recovery. Follow best practices and patterns available from the relevant cloud provider.</p>"},{"location":"design-authority/principles/cloud-and-infrastructure/#design-for-performance","title":"Design for performance","text":"<p>Design applications and infrastructure to ensure that they meet user response time expectations and can grow and adapt to changes in demand.</p>"},{"location":"design-authority/principles/cloud-and-infrastructure/#consider-open-source-first","title":"Consider open-source first","text":"<p>Optimise use of Open-Source vs Proprietary products. Choose the most economically advantageous solution.</p>"},{"location":"design-authority/principles/cloud-and-infrastructure/#simplify-and-standardise","title":"Simplify and standardise","text":"<p>Avoid technology sprawl. Balance the supportability implications of technology choices with the benefits of using unfamiliar technologies.</p>"},{"location":"design-authority/principles/data-and-analytics/","title":"Data &amp; Analytics Principles","text":"<p>Approved</p> <p>These principles have been approved by the DHCW TDA</p>"},{"location":"design-authority/principles/data-and-analytics/#data-is-captured-once-and-reused","title":"Data is captured once and reused","text":"<p>Data is captured once and reused refers to the practice of collecting patient information (such as medical history, test results, and treatment plans) during an initial encounter and then using that data throughout the patient\u2019s care journey. This approach aims to improve efficiency, reduce duplication, and enhance continuity of care.</p>"},{"location":"design-authority/principles/data-and-analytics/#data-is-semantically-interoperable","title":"Data is semantically interoperable","text":"<p>Data is not only syntactically consistent (i.e. formatted correctly) but also semantically consistent. Different systems can understand and interpret the data in the same way because the data carries the same meaning across systems. For example, a diagnosis code or a medication name will be interpreted correctly regardless of the system accessing it.</p>"},{"location":"design-authority/principles/data-and-analytics/#data-for-analytical-use-is-not-an-after-thought","title":"Data for analytical use is not an after thought","text":"<p>Secondary uses of data is integral to the design of any new applications. Publishing data to analytical stores must be included prior to deployment.</p>"},{"location":"design-authority/principles/data-and-analytics/#data-is-secured","title":"Data is secured","text":"<p>Data is compliant with security, regulatory and privacy requirements. Appropriate measures have been implemented to protect it from unauthorised access, disclosure, alteration, or destruction. Data security involves safeguarding sensitive information and ensuring its confidentiality, integrity, and availability.</p> <p>This can be achieved through various technical, organisational, and procedural controls, such as encryption, access controls, authentication mechanisms, data backups, and security monitoring. Effective data security practices aim to mitigate risks associated with data breaches, cyber attacks, insider threats, and other security vulnerabilities, thereby safeguarding the privacy, trust, and reputation of individuals and organisations.</p>"},{"location":"design-authority/principles/data-and-analytics/#data-is-findable-accessible-and-well-described","title":"Data is findable, accessible and well described","text":"<p>Data should be easy to find for both humans and computers. These data should be well described through comprehensive metadata and should include metrics relating to data quality and coverage. Data should be easily discoverable, available for authorised users, and accompanied by detailed documentation that enhances its understanding and usability.</p>"},{"location":"design-authority/principles/data-and-analytics/#data-is-high-quality","title":"Data is high quality","text":"<p>Data quality is monitored and reported. High-quality data serves as a reliable foundation for analysis, decision-making, and insights generation. It instils confidence in the results derived from data-driven processes and provides the opportunity to derive maximum value from data assets.</p>"},{"location":"design-authority/principles/digital-products-and-software-engineering/","title":"Digital Products &amp; Software Engineering Principles","text":"<p>Warning</p> <p>These principles are not yet approved by the DHCW TDA</p>"},{"location":"design-authority/principles/digital-products-and-software-engineering/#introduction","title":"Introduction","text":"<p>These principles guide the design, development, delivery, and lifecycle management of digital products and software. They operate within the framework set by the overarching Architecture Principles and aim to ensure that our digital solutions are valuable, user-focused, high-quality, sustainable, and aligned with strategic objectives.</p>"},{"location":"design-authority/principles/digital-products-and-software-engineering/#deliver-measurable-value-continuously","title":"Deliver Measurable Value Continuously","text":"<p>Digital products and software must demonstrably meet user needs and organisational strategic objectives. Development efforts should prioritise features that deliver the highest value, released iteratively to enable rapid feedback and adaptation.</p> Rationale <p>Focusing on continuous value delivery ensures that resources are applied effectively, benefits are realised sooner, and products evolve in line with changing requirements and priorities within the dynamic health and care landscape.</p> Implications <ul> <li>Adopt agile and lean methodologies (e.g., Scrum, Kanban) for product     development and delivery.</li> <li>Define clear value propositions, key performance indicators (KPIs), and     success metrics for all digital initiatives.</li> <li>Prioritise backlogs based on value, risk, learning opportunities, and     dependencies.</li> <li>Embrace frequent, small, and incremental releases to gather feedback     and deliver value early.</li> <li>Establish robust feedback loops with users, clinicians, and     stakeholders throughout the product lifecycle.</li> <li>Product roadmaps are living documents, regularly reviewed and adjusted     based on feedback and value realisation.</li> </ul>"},{"location":"design-authority/principles/digital-products-and-software-engineering/#user-needs-drive-product-evolution","title":"User Needs Drive Product Evolution","text":"<p>The ongoing development and evolution of digital products must be guided by a deep and empathetic understanding of user needs, behaviours, workflows, and feedback within the specific context of health and care in Wales.</p> Rationale <p>While (User-Centred Design principles](../user-centred-design/index.md) focus on the how of designing for users, this principle emphasises that what we build and how it evolves is continuously validated against real user requirements to ensure fitness for purpose and positive impact on health and care outcomes.</p> Implications <ul> <li>Integrate user research (e.g., interviews, observations, surveys) and     usability testing as continuous activities throughout the product     lifecycle.</li> <li>Develop and maintain clear user personas, user stories, and journey maps     relevant to Welsh health and care pathways.</li> <li>Utilise data analytics and user feedback mechanisms to understand user     behaviour, identify pain points, and measure satisfaction.</li> <li>Product backlogs and feature development are directly informed and     prioritised by validated user needs and evidence from diverse user     groups.</li> <li>Ensure services are simple to use, accessible, and inclusive, meeting     relevant standards and supporting both Welsh and English languages.</li> </ul>"},{"location":"design-authority/principles/digital-products-and-software-engineering/#engineer-for-quality-resilience-and-maintainability","title":"Engineer for Quality, Resilience, and Maintainability","text":"<p>Software must be robust, secure, performant, and easy to maintain and evolve over its lifecycle to ensure long-term viability, minimise technical debt, and reduce the total cost of ownership, which is especially critical for systems supporting health and care services.</p> Rationale <p>High-quality engineering practices lead to more reliable, secure, and adaptable systems that can better respond to future needs without excessive rework or risk.</p> Implications <ul> <li>Adhere to approved coding standards, architectural patterns, and software     development best practices.</li> <li>Implement comprehensive and automated testing strategies, including unit,     integration, contract, performance, and security testing.</li> <li>Conduct regular, constructive code reviews and proactive refactoring to     improve code quality and manage technical debt.</li> <li>Design for modularity, loose coupling, and high cohesion to facilitate     independent development, deployment, and scalability of components.</li> <li>Embed security considerations throughout the software development     lifecycle (DevSecOps), aligning with Security &amp; Identity principles.</li> <li>Apply rigorous clinical risk management throughout the software lifecycle     for any product with potential clinical impact, adhering to relevant      clinical safety standards and regulatory requirements.</li> <li>Ensure systems are designed for observability (comprehensive logging,     monitoring, tracing, and alerting) to support operational stability and     rapid issue resolution.</li> <li>Strive for resource-efficient software design and implementation to     minimise environmental impact, aligning with sustainability goals.</li> <li>Document software architecture and design decisions clearly and keep      documentation up-to-date.</li> </ul>"},{"location":"design-authority/principles/digital-products-and-software-engineering/#embrace-agile-and-devops-culture-and-practices","title":"Embrace Agile and DevOps Culture and Practices","text":"<p>Foster a collaborative, communicative, and continuously improving culture, supported by DevOps practices, to enable rapid, reliable, and sustainable delivery of high-quality digital products and software.</p> Rationale <p>An agile and DevOps approach breaks down silos, improves flow, automates processes, and empowers teams, leading to faster delivery cycles, higher quality, increased innovation, and better responsiveness to evolving needs.</p> Implications <ul> <li>Promote the formation of empowered, cross-functional teams with shared     ownership and accountability.</li> <li>Implement robust CI/CD pipelines to automate build, testing, and     deployment processes.</li> <li>Encourage open communication, knowledge sharing, and collaborative     problem-solving within and between teams.</li> <li>Leverage endorsed collaboration tools and platforms to enhance teamwork     and knowledge sharing, in alignment with Digital Workplace principles     where applicable.</li> <li>Adopt \"you build it, you run it\" philosophies where appropriate, with     teams taking responsibility for the operational support of their     services.</li> <li>Conduct regular retrospectives and experiments to continuously learn,     adapt, and improve processes, tools, and team practices.</li> <li>Champion psychological safety to encourage experimentation and learning     from failures.</li> </ul>"},{"location":"design-authority/principles/digital-products-and-software-engineering/#leverage-reusability-and-promote-interoperability","title":"Leverage Reusability and Promote Interoperability","text":"<p>Maximise efficiency, consistency, and integration capabilities by identifying, creating, and utilising common components, services, platforms, and data standards. Design systems to interoperate seamlessly within the ecosystem and with authorised external systems.</p> Rationale <p>Reusability reduces duplication of effort, accelerates delivery, and lowers costs. Interoperability is fundamental for a connected health and care system, enabling data to flow securely and efficiently where it's needed.</p> Implications <ul> <li>Prioritise the use of existing approved platforms, APIs, shared services,     and common libraries.</li> <li>Develop new components and services with reusability and clear interface     contracts (e.g. APIs) in mind.</li> <li>Adhere to established national and international interoperability     standards relevant to health and care (e.g., HL7 FHIR, openEHR where     appropriate).</li> <li>Maintain and contribute to a catalogue of reusable assets, APIs, and data     models.</li> <li>Employ API-first design strategies to facilitate integration and enable a     composable enterprise.</li> <li>Ensure data is exchanged using agreed-upon formats and semantics,     aligning with Data &amp; Analytics principles.</li> </ul>"},{"location":"design-authority/principles/digital-products-and-software-engineering/#make-data-informed-product-and-technical-decisions","title":"Make Data-Informed Product and Technical Decisions","text":"<p>Product strategies, feature prioritisation, architectural choices, and engineering improvements should be guided by objective data and evidence, rather than solely by assumptions or opinions.</p> Rationale <p>Using data to inform decisions reduces risk, helps to validate hypotheses, optimises resource allocation, and ensures that efforts are focused on areas that will yield the most significant impact for users.</p> Implications <ul> <li>Instrument applications and systems to collect relevant operational data,     user analytics, and performance metrics.</li> <li>Establish and monitor Key Performance Indicators (KPIs) and Service Level     Objectives (SLOs) for digital products and services.</li> <li>Regularly analyze collected data to identify trends, insights, user     behaviours, system bottlenecks, and areas for improvement.</li> <li>Utilize A/B testing, canary releases, and other experimentation     techniques to validate changes and guide product evolution where     appropriate.</li> <li>Ensure that data used for decision-making is accurate, timely, and     relevant, and that its collection and use comply with data privacy and     governance policies.</li> </ul>"},{"location":"design-authority/principles/digital-products-and-software-engineering/#manage-technology-pragmatically-and-sustainably","title":"Manage Technology Pragmatically and Sustainably","text":"<p>Technology choices must be driven by fitness for purpose, long-term sustainability, alignment with the strategic technology roadmap, security requirements, and total cost of ownership, rather than by novelty or individual preference.</p> Rationale <p>Pragmatic technology management ensures that we invest in solutions that are supportable, scalable, secure, and cost-effective over their intended lifespan, minimising risks associated with obsolescence or niche skill dependencies, and aligning with overarching Architecture Principles.</p> Implications <ul> <li>Follow a \"reuse before buy, buy before build\" approach: prioritise     reusing existing or publicly available solutions (including open source     with appropriate support), then consider acquiring commercial     off-the-shelf products, before commissioning new bespoke development,      as guided by Architecture Principles.</li> <li>Evaluate technologies using clear criteria, including maturity,     community/vendor support, security posture, scalability, performance,     interoperability, skills availability, and alignment with existing     technology stacks.</li> <li>Favor proven technologies, open standards, and solutions that align with     the Cloud &amp; Infrastructure principles.</li> <li>Proactively manage technical debt: identify, prioritise, and address it     systematically.</li> <li>Consider the full lifecycle implications of technology choices, including     development, deployment, operations, maintenance, and eventual     decommissioning.</li> <li>Maintain a clear technology radar and roadmap, regularly reviewing and     updating it based on our evolving needs and the technology landscape.</li> <li>Ensure that skills and knowledge for chosen technologies are developed     and maintained.</li> </ul>"},{"location":"design-authority/principles/digital-workplace/","title":"Digital Workplace Principles","text":"<p>Approved</p> <p>These principles have been approved by the DHCW TDA</p>"},{"location":"design-authority/principles/digital-workplace/#employee-experience-is-always-a-key-priority","title":"Employee experience is always a key priority","text":"<p>When designing, implementing, configuring or procuring products for the Digital Workplace, the employee (end-user) experience is always a key priority. Systems should be designed to meet user needs. Staff need to have the right tools for the right job.</p>"},{"location":"design-authority/principles/digital-workplace/#support-must-be-proactive-in-nature-and-driven-by-data","title":"Support must be proactive in nature and driven by data","text":"<p>Proactive support reduces avoidable downtime and service disruption for our employees. Monitoring the user experience and underpinning infrastructure enables a shift to more proactive incident and problem management.</p>"},{"location":"design-authority/principles/digital-workplace/#flexibility-to-work-effectively-from-multiple-locations-and-on-multiple-devices","title":"Flexibility to work effectively from multiple locations and on multiple devices","text":"<p>Employees will have the same rich digital workplace experience from all approved locations, whether from a DHCW office, other NHS premises or a location with only internet access, and from any approved device.</p> <p>Solutions must be designed to support an optimal hybrid-working experience and employees who have a blended work pattern (office, home/remote).</p>"},{"location":"design-authority/principles/digital-workplace/#the-digital-workplace-exploits-ai-and-automation","title":"The Digital Workplace exploits AI and Automation","text":"<p>AI and automation supports and augments the work of the employee, freeing up time for higher-value work and improved employee wellbeing.</p>"},{"location":"design-authority/principles/digital-workplace/#adopt-modern-technologies-and-best-practices","title":"Adopt modern technologies and best practices","text":"<p>Modern technologies and practices provide a richer digital experience for employees, allowing them to benefit from the latest features and services to support them in their work.</p>"},{"location":"design-authority/principles/digital-workplace/#security-as-an-enabler","title":"Security as an enabler","text":"<p>Robust security measures must be implemented to both protect data and resources, but also facilitate enhanced production, collaboration and innovation.</p>"},{"location":"design-authority/principles/digital-workplace/#digital-first","title":"Digital First","text":"<p>Systems and processes that support the Digital Workplace should be digital by design, reducing and eventually removing the need for manual alternatives.</p>"},{"location":"design-authority/principles/digital-workplace/#reduce-the-carbon-footprint","title":"Reduce the Carbon Footprint","text":"<p>Reducing the carbon footprint of the Digital Workplace is essential to support decarbonisation goals.</p>"},{"location":"design-authority/principles/digital-workplace/#supporting-the-accessibility-needs-of-workforce","title":"Supporting the accessibility needs of workforce","text":"<p>Systems that underpin the Digital Workplace must enable all staff to work to the best of their abilities and support any staff with particular needs.</p>"},{"location":"design-authority/principles/digital-workplace/#supporting-the-use-of-the-welsh-language","title":"Supporting the use of the Welsh Language","text":"<p>We will ensure that Welsh language interfaces and supporting technology is made easily available to our users. Welsh language requirements will be included as part of the procurement for relevant services.</p>"},{"location":"design-authority/principles/digital-workplace/#internet-first","title":"Internet First","text":"<p>When designing, implementing, configuring or procuring products for the Digital Workplace.</p>"},{"location":"design-authority/principles/open-architecture/","title":"Open Architecture &amp; Integration Principles","text":"<p>Approved</p> <p>These principles have been approved by the DHCW TDA</p>"},{"location":"design-authority/principles/open-architecture/#api-first","title":"API First","text":"<p>APIs will be the primary interface through which our platforms and products interact and exchange data.</p>"},{"location":"design-authority/principles/open-architecture/#open-architecture","title":"Open Architecture","text":"<p>Our architecture will be open, enabled by discoverable, well documented, standards based and reusable APIs and governed by appropriate and proportionate onboarding processes.</p>"},{"location":"design-authority/principles/open-architecture/#open-standards","title":"Open Standards","text":"<p>Interactions and data exchange between platforms and products will be based on open standards by default.</p>"},{"location":"design-authority/principles/open-architecture/#secure-by-design","title":"Secure by Design","text":"<p>Our APIs, platforms and products will be designed and built to be secure from the ground up.</p>"},{"location":"design-authority/principles/open-architecture/#shift-assurance-left","title":"Shift assurance left","text":"<p>Assurance, governance and quality will be built into our platforms and products from the ground up.</p>"},{"location":"design-authority/principles/open-architecture/#user-centric-focused-on-value","title":"User centric &amp; focused on value","text":"<p>Platforms and products will be designed with our users in mind and architecture decisions will consider what will generate the best return of value in the long run.</p>"},{"location":"design-authority/principles/open-architecture/#flexible-modular-scalable","title":"Flexible, Modular &amp; Scalable","text":"<p>We will design our platforms and products to be flexible, modular and scalable.</p>"},{"location":"design-authority/principles/security-and-identity/","title":"Identity &amp; Security Principles","text":""},{"location":"design-authority/principles/security-and-identity/#security-as-an-enabler","title":"Security as an enabler","text":"<p>Security should be viewed not as a barrier but a fundamental element that supports and enhances business objectives, innovation, and operation efficiency. Robust security measures will enable agility and trust.</p>"},{"location":"design-authority/principles/security-and-identity/#minimum-effective-toolset","title":"Minimum effective toolset","text":"<p>Use the smallest number of tools and solutions necessary to achieve security objective effectively.</p>"},{"location":"design-authority/principles/security-and-identity/#secure-supply-chain","title":"Secure supply chain","text":"<p>Ensure the supply chain is secured by ensuring the security, integrity and reliability of all parties responsible for delivery of services or products. This will involve an assessment of  security controls and standards of a supplier, and their incident response plans and capability.</p>"},{"location":"design-authority/principles/security-and-identity/#assume-when-not-if","title":"Assume when not if","text":"<p>Instead of assuming a security breach might happen, DHCW must assume it will happen and plan accordingly. This will mean elevating response and recovery capabilities to the same status of detection and prevention.</p>"},{"location":"design-authority/principles/security-and-identity/#design-for-isolation-where-possible","title":"Design for Isolation where possible","text":"<p>Systems, applications and processes should be compartmentalised where possible. Systems, applications and processes should be designed to isolate components and restrict their interaction unless explicitly required.</p>"},{"location":"design-authority/principles/security-and-identity/#zero-trust","title":"Zero Trust","text":"<p>No device, user or system should be automatically trusted whether inside or outside the network perimeter, and must be given the minimum access necessary to complete their tasks (least privilege). All interactions must be monitored and audited.</p>"},{"location":"design-authority/principles/security-and-identity/#defence-in-depth","title":"Defence in depth","text":"<p>Multiple layers of security controls and measures must be implemented to protect systems, infrastructure and data.</p>"},{"location":"design-authority/principles/security-and-identity/#secure-by-design","title":"Secure by Design","text":"<p>Security must be incorporated into the design and development process of systems, infrastructure and applications from the start of the project, rather than considering security late in the design lifecycle.</p>"},{"location":"design-authority/principles/security-and-identity/#single-source-of-truth","title":"Single source of truth","text":"<p>All users, applications and systems rely on a single, consistent, and authoritative source for authentication and user data.</p>"},{"location":"design-authority/principles/security-and-identity/#verify-then-trust-emerging-technologies","title":"Verify then Trust Emerging Technologies","text":"<p>New technology such as GenAI must be comprehensively evaluated and validated before use by DHCW, particularly for critical systems.</p>"},{"location":"design-authority/principles/security-and-identity/#simple-as-possible","title":"Simple as Possible","text":"<p>Minimise the complexity of the design, implementation and management of systems, applications and processes where possible. Use validated or previously used successful designs where possible.</p>"},{"location":"design-authority/principles/user-centred-design/","title":"User-Centred Design (UCD) Principles","text":"<p>Note</p> <p>These principles are not yet approved by the DHCW TDA</p>"},{"location":"design-authority/principles/user-centred-design/#start-with-user-needs","title":"Start with user needs","text":"<p>Test your assumptions.</p> <p>Public services are for everyone and must be driven by user needs.</p> <p>User research prevents wasted resources and reveals real problems, enabling evidence-based, cost-effective decisions.</p>"},{"location":"design-authority/principles/user-centred-design/#design-with-data","title":"Design with  data","text":"<p>Use data to make decision.</p> <p>Continuously monitor service performance and use data and user feedback to prioritise improvements and identify problems that need to be fixed</p>"},{"location":"design-authority/principles/user-centred-design/#do-the-hard-work-to-make-it-simple-and-inclusive","title":"Do the hard work to make it simple and inclusive","text":"<p>Make the service easy to use and make sure everyone can use it.</p> <p>Design inclusively, ensuring easy access for all, including those often excluded.</p> <p>Healthcare can be complex. Do the hard work to make it simpler</p>"},{"location":"design-authority/principles/user-centred-design/#design-for-outcome-and-context","title":"Design for outcome and context","text":"<p>Consider what good will look like, how it fits with the entire services, and how you will measure outcomes.</p> <p>Understand users and their needs in the context of health and care.</p>"},{"location":"design-authority/principles/user-centred-design/#iterate-learn-improve","title":"Iterate. Learn, Improve","text":"<p>Use an incremental, fast-paced approach to get working products into users\u2019 hands as early as possible, as often as possible.</p> <p>Rapidly iterate and focus on the improvements that have the most value, based on user feedback.</p>"},{"location":"design-authority/principles/user-centred-design/#make-things-open-and-consistent","title":"Make things open and consistent","text":"<p>Use and contribute to open standards, common components and patterns and share what you\u2019re doing whenever you can.</p>"},{"location":"design-authority/principles/user-centred-design/#design-services-in-welsh-and-english","title":"Design services in Welsh and English","text":"<p>Design and build services that promote and ease the use of Welsh and treat those who speak it equally with those who speak English.</p>"},{"location":"design-authority/principles/user-centred-design/#design-for-trust","title":"Design for trust","text":"<p>Services must be secure and safe to maintain users\u2019 trust.</p> <p>Digital information, tools and services have the potential to cause patient harm.</p> <p>Respect and protect users' confidentiality and privacy.</p>"},{"location":"design-authority/principles/user-centred-design/#minimise-environmental-impact","title":"Minimise environmental impact","text":"<p>The climate crisis is a health crisis.</p> <p>Follow sustainability best practice to reduce the environmental impact of your service across its lifespan.</p>"},{"location":"git-organizations/","title":"Git organizations","text":"<p>Status: first sketch, work in progress, request for collaboration</p> <p>Date: Updated 2025-04-04</p> <p>Governance: To Be Discovered; potentially a combo of this repo partipants, DHCW CISO, NHS Wales UCB peers, etc.</p>"},{"location":"git-organizations/#situation-context-and-problem-statement","title":"Situation - Context and Problem Statement","text":"<p>Generally we aim to encourage principles of public health, public health code, public health data, public health participation, and public health involvement.</p> <p>Specifically Joel needs to immediately work on the emergency department module authentication demonstration, which involves external Microsoft Entra free accounts, all fake data for testing purposes, and open for partners and advisors especially Microsoft, Kainos, Capacitas, NCSC. The immediate next project is radiology test automation with rapid setup of fake data such as via external FHIR services.</p> <p>Joel is delivering these via a public health free open source git organization. This is a new capability for NHS Wales and for DHCW, based on best practices for U.S. healthcare companies that have a bright-line divider between their external-public-free-open-source and their internal-private-expensed-closed-source.</p> <p>Dan wants to use the learnings that come from these, in order to improve the internal systems.</p>"},{"location":"git-organizations/#background-decision-drivers","title":"Background - Decision Drivers","text":"<p>Joel's decision drivers are the typical best practices in the U.S. and E.U. which is to create a bright-line information security separation between two categories of work:</p> <ol> <li> <p>Category one is for the public. This includes things like demonstrations, examples, tutorials, free open source software, fake testing information, data that is free and clear of any personally identifying information, etc.</p> </li> <li> <p>Category two is for employees. This includes things like internal-only applications, employment records, paid closed source software, personally identifiable information (PII), confidential documents, security secrets, and the like.</p> </li> </ol> <p>This is the approach taken by organizations such as Apple, Microsoft, Google, etc. and it improves security with U.S. SOC 2 compliance, the EU Cybersecurity Act, the  International Standards Organization (ISO) 27001 information security framework, etc.</p> <p>Dan's decision drivers are TODO @Dan.</p>"},{"location":"git-organizations/#decision-driver-questions","title":"Decision Driver Questions","text":"<p>One of the areas we're exploring as a group on our chat is coming up with questions that can help us assess options.</p> <p>Here are  some questions that we're considering thus far.</p> <p>TODO @Joel add questions here.</p> <p>TODO @Dan add questions here.</p>"},{"location":"git-organizations/#assessment-considered-options","title":"Assessment - Considered Options","text":"<p>Option 1: Our current path.</p> <ul> <li> <p>Joel and DevOps continue to use the category one GitHub repo.</p> </li> <li> <p>Dan and NDR continue to use the category 2 GitHub repo, plus do anything they want to improve the internal systems.</p> </li> <li> <p>We update each other about learnings as we go.</p> </li> <li> <p>We revisit together later on, such as after the emergency department module ships and the radiology testing ships.</p> </li> </ul> <p>Option 2: TODO @Dan.</p>"},{"location":"git-organizations/#recommendation-decision-outcome","title":"Recommendation - Decision Outcome","text":"<p>TODO</p>"},{"location":"hosting-data-in-the-united-states-or-the-united-kingdom/","title":"Hosting data in the United States or the United Kingdom","text":"<p>Note</p> <p>Work in Progress</p> <p>Status: first sketch, work in progress, request for collaboration</p> <p>Date: Updated 2025-04-08</p> <p>Governance: To Be Discovered; potentially a combo of this repo participants, DHCW CISO, NHS Wales UCB peers, etc.</p>"},{"location":"hosting-data-in-the-united-states-or-the-united-kingdom/#context","title":"Context","text":"<p>Our organisation stakeholders are asking questions about hosting data in the United States versus the United Kingdom.</p> <p>The decision will have significant implications for data security, compliance with legal and regulatory requirements, performance (e.g., latency), cost, risk, piloting, and more.</p> <p>We want to learn more about how to make a well-informed choice between hosting the data in one of these countries, considering the current needs and potential future growth.</p> <p>We also want to learn more about hosting in both regions, such as using a multi-cloud approach.</p> <ul> <li>We believe there are tradeoffs compliance and operational efficiency.</li> </ul> <p>We also want to learn more about hosting in the EU region, such as using a European hosting company.</p> <ul> <li> <p>There may be benefits of EU scale/cost/capabilities over the UK. For example, Germany may offer larger-scale, better-cost, faster-deployment, etc. than the UK.</p> </li> <li> <p>There may be EU law/harmonization/openness as compared to the US. For example, the EU has better legal harmony with the UK relating to GDPR, ISO 27001, etc.</p> </li> </ul>"},{"location":"hosting-data-in-the-united-states-or-the-united-kingdom/#drivers","title":"Drivers","text":"<p>We intend to research this area more in depth.</p> <p>Data Sovereignty and Compliance:</p> <ul> <li> <p>U.K.: Hosting in the U.K. offers compliance with the General Data Protection Regulation (GDPR), ensuring data privacy and protection. As the U.K. is no longer part of the EU, there are unique data protection regulations, but they are still aligned with GDPR principles.</p> </li> <li> <p>U.S.: The U.S. follows a more fragmented approach to data privacy and protection regulations, with different states having their own laws (e.g., CCPA in California). U.S. regulations may be less stringent than those in the E.U. and U.K., particularly in areas like consumer rights over data.</p> </li> </ul> <p>International Data Transfers:</p> <ul> <li> <p>U.K.: The U.K. provides more certainty for international data transfers, as it follows a similar framework to the EU's GDPR for cross-border data flow. There is also the UK-EU adequacy decision, which means data can be transferred between the U.K. and the EU without needing additional safeguards.</p> </li> <li> <p>U.S.: Data transfers from the EU/UK to the U.S. are subject to stricter scrutiny, and compliance with frameworks like the EU-U.S. Data Privacy Shield (though invalidated in 2020) or Standard Contractual Clauses (SCCs) is required for lawful data transfer. The U.S. may require more legal efforts and complex agreements around data transfer.</p> </li> </ul> <p>Latency and Performance:</p> <ul> <li> <p>U.K.: Hosting in the U.K. is ideal if the user base is primarily located in Europe or other parts of the world that have low-latency access to the U.K. data centers. This can result in better response times for users in these regions.</p> </li> <li> <p>U.S.: If the majority of the user base is based in North America, hosting in the U.S. might offer lower latency and better performance for those users.</p> </li> </ul> <p>Cost:</p> <ul> <li> <p>U.K.: Hosting in the U.K. may be more expensive due to higher energy costs, data center hosting fees, and regional operational expenses. However, this could be offset by the benefits of regulatory compliance.</p> </li> <li> <p>U.S.: The U.S. is often considered a more affordable location for data hosting due to lower operational costs in many regions (e.g., server hosting, energy, etc.). Certain providers may offer cost-effective hosting options, especially for large-scale operations.</p> </li> </ul> <p>Legal and Political Environment:</p> <ul> <li> <p>U.K.: The U.K. offers a stable political environment, though post-Brexit regulations and trade agreements may introduce some uncertainty around data sovereignty.</p> </li> <li> <p>U.S.: The U.S. has a well-established legal framework for technology and data, but its approach to data privacy and government surveillance (e.g., FISA and Patriot Act) may raise concerns, particularly in Europe or with users who prioritize data privacy.</p> </li> </ul> <p>Future Considerations:</p> <ul> <li> <p>U.K.: As a key player in the global economy, the U.K. will likely remain a strong choice for hosting for years to come, especially given its alignment with GDPR-like regulations.</p> </li> <li> <p>U.S.: Depending on future political shifts and regulatory changes, hosting in the U.S. might face stricter scrutiny and regulatory changes, particularly for businesses with international customers.</p> </li> </ul>"},{"location":"hosting-data-in-the-united-states-or-the-united-kingdom/#recommendation-decision-outcome","title":"Recommendation - Decision Outcome","text":"<p>TODO</p>"},{"location":"hosting-data-in-the-united-states-or-the-united-kingdom/#consequences","title":"Consequences","text":"<p>We intend to research this area more in depth.</p> <p>U.K.:</p> <ul> <li> <p>Easier to comply with GDPR-like regulations and to transfer data across EU borders.</p> </li> <li> <p>Potentially higher costs due to the region\u2019s operational overhead.</p> </li> <li> <p>Low latency for European users.</p> </li> </ul> <p>U.S.:</p> <ul> <li> <p>Potentially cheaper but may require more complex regulatory agreements for international data transfer.</p> </li> <li> <p>Increased latency for European users.</p> </li> <li> <p>More fragmented privacy laws and potential surveillance concerns.</p> </li> </ul>"},{"location":"knowledge/","title":"Knowledge","text":"<p>Note</p> <p>Work in Progress</p> <p>Status: first sketch, work in progress, request for collaboration</p> <p>Date: 2025-03-21</p> <p>Governance: To Be Discovered; potentially a combo of this repo participants, DHCW CISO, NHS Wales UCB peers, etc.</p>"},{"location":"knowledge/#context","title":"Context","text":"<p>Broadly, our organization aims to improve our knowledge building and knowledge sharing. For example, we have major multi-year work fronts to create our medical software with domain knowledge, to improve software engineering with programming knowledge, to widen our data research needs with statistical knowledge, and to innovate our AI adoption with machine learning knowledge. Knowledge work can be improved by better ways of working and by software for knowledge management systems (KMS).</p> <p>Specifically, right now for the emergency department module, Joel is discovering that knowledge within the organization tends to be tribal and trapped in internal systems. In the past week, Joel and teammates have had total knowledge misses, meaning our people know the work exists but can't find it or can't share it. This causes delays, confusions, frustrations, and unnecessary redos. Joel and the software engineers need ways to find documentation and share it with each other.</p>"},{"location":"knowledge/#drivers","title":"Drivers","text":"<p>We want to immediately increase our capabilities to create knowledge, find it, share it, and update it. We want to do this immediately for knowledge for the emergency department module and it's related software engineering work.</p> <p>A couple of pieces where Joel believes better knowledge management is urgent for this specific project:</p> <ol> <li> <p>Authentication such as for our use cases, which also will lead into authentication for more of our software engineering projects.</p> </li> <li> <p>Reification, which means we \"make real\" the various high-level knowledge that we have in hand, so we can ship real code faster, then iterate on the knowledge and the code.</p> </li> </ol> <p>A couple of ways of working that we believe are lightweight and can help right now:</p> <ol> <li> <p>Shifting what we can from private-first to public-first. For example, shifting from intranet knowledge to more extranet knowledge. Newer ways of working include us working in the open on ADRs such as this one, as well as our new public GitHub organization, and our relationships with peer organizations including NHS England, GOV.UK, UK NCSC, etc.</p> </li> <li> <p>Shifting what we can from must-be-perfect to could-be-good-enough. For example, shifting documentation from a many-day many-tier many-person approval process of a final finished gorgeous PowerPower to a few-hour few-person approval process of a first draft of a markdown text file.</p> </li> </ol> <p>A couple of knowledge management systems that we believe are lightweight and can help right now:</p> <ol> <li> <p>Something TBD for upskilling our team. We have multiple inbound requests from staff about how to learn GitHub to work on ADRs, how to use AI code assistants to speed up boilerplate programming, how to share work-in-progress documentation URLs with our peer organizations, etc.</p> </li> <li> <p>Something TBD for tagging and searching for knowledge. We have need obvious tags such as for software engineering topics (e.g. #authentication, #authorization), software tools (e.g. #git, #copilot), software languages (e.g. #javascript, #python).</p> </li> </ol> <p>Business drivers:</p> <ol> <li>The organization needs a way to ensure knowledge is not only captured but also shared effectively among all employees. Knowledge sharing is essential for innovation, problem-solving, and continuous learning across departments.</li> </ol>"},{"location":"knowledge/#options","title":"Options","text":"<p>Knowledge is a massive topic, so we want to quickly sketch some options for us to consider.</p>"},{"location":"knowledge/#formal-synchronous-knowledge-sharing","title":"Formal synchronous knowledge-sharing","text":"<p>Examples: webinars, workshops, upskilling sessions, training programs.</p> <p>Resources: typically these work best when there is dedicated time, equipment, rooms, and people.</p> <p>Example pros: High-quality, structured content; clear focus on knowledge dissemination.</p> <p>Example cons: Time-consuming; could be difficult to maintain long-term.</p>"},{"location":"knowledge/#informal-asynchronous-knowledge-sharing","title":"Informal asynchronous knowledge-sharing","text":"<p>Examples: collaboration tools and communication platforms, such as wikis, blogs, chats, virtual whiteboards, kanban boards, etc.</p> <p>Resources: typically these work best when there is organizational IT capability for setup, ongoing tuning, and scaling.</p> <p>Example pros: Easier to scale; integrates well with daily work; encourages spontaneous knowledge sharing.</p> <p>Example cons: Lack of structure may lead to fragmented knowledge sharing; less formalized tracking.</p>"},{"location":"knowledge/#hybrid-formalinformal-knowledge-sharing","title":"Hybrid formal/informal knowledge-sharing","text":"<p>Examples: a quarterly presentation about a topic that aligns with an ongoing chat channel where people can ask questions, share links, etc.</p> <p>Resources: as above.</p> <p>Example pros: Combines the best of both worlds; structured programs for high-priority topics, while also allowing organic knowledge sharing.</p> <p>Example cons: More complex to implement; people might miss out on knowledge in one of the presentations or one of the channels, without realizing it.</p>"},{"location":"knowledge/#system-quality-attributes-to-consider","title":"System quality attributes to consider","text":"<p>Usability: Team members need to be able to easily contribute, edit, and interact with the knowledge base.</p> <p>Flexibility: The solution must accommodate both structured and informal ways of sharing knowledge.</p> <p>Searchability: The ability to search through documents and retrieve relevant information quickly is essential.</p> <p>Scalability: The system must be able to handle increasing amounts of data as the organization grows.</p> <p>Security: Sensitive information must be stored securely, with access control in place.</p> <p>Integrability: The system should integrate well with other internal tools (e.g., document management systems, chat apps, etc.).</p>"},{"location":"knowledge/#consequences","title":"Consequences","text":"<p>Examples that we want to know more about...</p> <p>Positive:</p> <ul> <li> <p>Employees will have multiple avenues to share knowledge, which increases engagement.</p> </li> <li> <p>Combining formal and informal approaches allows for scalability while maintaining quality.</p> </li> <li> <p>By using communication platforms like Slack, employees can seamlessly share knowledge in real-time, fostering continuous learning.</p> </li> </ul> <p>Negative:</p> <ul> <li> <p>Maintaining engagement could become challenging if the initiative is not properly supported by leadership.</p> </li> <li> <p>Lack of structure in informal sharing may result in valuable knowledge being lost or overlooked.</p> </li> </ul>"},{"location":"knowledge/#recommendations","title":"Recommendations","text":"<p>Start right now with lightweight ways of working and lightweight documentation tooling.</p> <p>Use these as landing zones:</p> <ol> <li> <p>Create our new external GitHub organization, with new public repositories, where we add new documentation, code, tests, etc. Share it among staff, and peer organizations, and the general public.</p> </li> <li> <p>Favor simple open formats and simple open standards for good-enough knowledge discussion, such as favoring text files over PowerPoint, ADRs over SADs, ad-hoc tagging with \"#tag\" syntax over formal rigid hierarchical ontologies.</p> </li> <li> <p>Leverage free open source software for searching and indexing our external knowledge work. We're starting with mkdocs and iterating to add mkdocs-awesome-nav.</p> </li> </ol>"},{"location":"live-dora-metrics-dashboards/","title":"Live DORA Metrics Dashboards","text":"<p>Note</p> <p>Work in Progress</p> <p>Status: first sketch, work in progress, request for collaboration</p> <p>Date: Updated 2025-04-08</p> <p>Governance: To Be Discovered; potentially a combo of this repo participants, DHCW CISO, NHS Wales UCB peers, etc.</p>"},{"location":"live-dora-metrics-dashboards/#context","title":"Context","text":"<p>Broadly, our organization wants to improve the quality of our software engineering, and we want to do this by making software engineering metrics visible. We intend to start with the DevOps Research and Assessment (DORA) report because these are well-known, well-understood, and well-researched.</p>"},{"location":"live-dora-metrics-dashboards/#what-are-dora-metrics","title":"What are DORA Metrics?","text":"<p>https://dora.dev/guides/dora-metrics-four-keys/</p> <p>The DORA metics are:</p> <ul> <li> <p>Lead Time - This metric measures the time it takes for a code commit or change   to be successfully deployed to production. It reflects the efficiency of your   software delivery process.</p> </li> <li> <p>Deployment Frequency - This metric measures how often application changes are   deployed to production. Higher deployment frequency indicates a more efficient   and responsive delivery process.</p> </li> <li> <p>Change Failure - This metric measures the percentage of deployments that cause   failures in production, requiring hotfixes or rollbacks. A lower change   failure rate indicates a more reliable delivery process.</p> </li> <li> <p>Recovery Time a.k.a. Time to Restore Service a.k.a. Failed Deployment Reset   Time - This metric measures the time it takes to recover from a failed   deployment. A lower recovery time indicates a more resilient and responsive   system.</p> </li> </ul> <p>These metrics are in two categories:</p> <ul> <li> <p>Throughput: Lead Time &amp; Deployment Frequency.</p> </li> <li> <p>Stability: Change Failure &amp; Recovery Time.</p> </li> </ul>"},{"location":"live-dora-metrics-dashboards/#drivers","title":"Drivers","text":"<p>We want to develop a live dashboard to track our projects' DORA metrics. This dashboard will be used by software engineering teams, including our programmers, project managers, and all the project's other stakeholders.</p> <p>We believe this kind of visibility, transparency, and monitoring can help us improve our software engineering practices and outcomes.</p> <p>We believe the live DORA metrics dashboards will likely include the kinds of aspects below.</p> <p>Data Sources:</p> <ul> <li> <p>Git/CI/CD System to retrieve lead time, deployment frequency, change   failure rate, and recovery time.</p> </li> <li> <p>Incident Management Tools to help calculate the time to restore service.</p> </li> </ul> <p>Data Collection and ETL Process:</p> <ul> <li> <p>ETL (Extract, Transform, Load) pipelines to gather data from the above   systems, across projects, then aggregate it into a central data store.</p> </li> <li> <p>Data will be refreshed at regular intervals (e.g., every hour) to provide   usable daily-quality metrics.</p> </li> <li> <p>The collected data will be stored in a data store TBD. We may want to try a   Time-series Database (TSDB) rather than a relational database (RDB) because   time-series data may provide efficient querying and retrieval of time-based   metrics.</p> </li> </ul> <p>Backend Services:</p> <ul> <li> <p>A RESTful API will serve as the backend for the dashboard, handling   requests from the frontend.</p> </li> <li> <p>Authentication and authorization TBD.</p> </li> </ul> <p>Frontend (Dashboard):</p> <ul> <li> <p>The dashboard will be built using JavaScript/TypeScript for flexibility and   maintainability.</p> </li> <li> <p>Data visualization will be handled using an off-the-shelf charting library TBD.</p> </li> <li> <p>We'll consider developing the frontend to update dynamically based on data   changes via WebSockets or Server-Sent Events (SSE).</p> </li> </ul> <p>Monitoring and Alerts:</p> <ul> <li> <p>We may want to create alerts. For example, we may want to create alerts that   will be triggered when certain thresholds are exceeded (e.g., high failure   rate, slow recovery time). These alerts will be visible in the dashboard and   could also be pushed to our messaging system.</p> </li> <li> <p>We will also monitor the health of the dashboard itself.</p> </li> </ul>"},{"location":"live-dora-metrics-dashboards/#alternatives-considered","title":"Alternatives Considered","text":"<p>Manual data collection vs. automated ETL pipelines:</p> <ul> <li>Initially, we considered manually extracting metrics through scheduled   scripts, but this would be error-prone and less maintainable. The automated   ETL pipelines were chosen for their scalability and reliability.</li> </ul> <p>Using a traditional relational database vs. time-series database:</p> <ul> <li>We considered using a relational database (e.g., PostgreSQL) to store DORA   metrics, but time-series databases like InfluxDB offer optimized storage   and query performance for time-based data, making them a better choice for   this use case.</li> </ul> <p>*Frontend technologies:</p> <ul> <li>We evaluated using Vue.js or Angular for the frontend but decided on   React.js due to its widespread adoption, large community, and extensive   library support for real-time data visualization.</li> </ul>"},{"location":"live-dora-metrics-dashboards/#common-pitfalls","title":"Common pitfalls","text":"<p>From https://dora.dev/guides/dora-metrics-four-keys/</p> <p>There are some pitfalls to watch out for as your team adopts DORA\u2019s software delivery metrics, including the following:</p> <ul> <li> <p>Setting metrics as a goal. Ignoring Goodhart\u2019s law and making broad statements   like, \u201cEvery application must deploy multiple times per day by year\u2019s end,\u201d   increases the likelihood that teams will try to game the metrics.</p> </li> <li> <p>Having one metric to rule them all. Attempting to measure complex systems with   the idea that only one metric matters. Teams should identify multiple metrics,   including some with a healthy amount of tension between them. The SPACE   framework can guide your discovery of a set of metrics.</p> </li> <li> <p>Using industry as a shield against improving. For example, some teams in   highly regulated industries might claim that compliance requirements prevent   them from disrupting the status quo.</p> </li> <li> <p>Making disparate comparisons. These metrics are meant to be applied at the   application or service level. Comparing metrics between vastly different   applications (for example, a mobile app and a mainframe system) can be   misleading.</p> </li> <li> <p>Having siloed ownership. Sharing all four metrics across development,   operations, and release teams fosters collaboration and shared ownership of   the delivery process. Isolating teams with specific metrics can lead to   friction and finger-pointing.</p> </li> <li> <p>Competing. The goal is to improve your team\u2019s performance over time, not to   compete against other teams or organizations. Use the metrics as a guide for   identifying areas for growth and celebrating progress.</p> </li> <li> <p>Focusing on measurement at the expense of improvement. The data your team   needs to collect for the four keys is available in a number of different   places today. Building integrations to multiple systems to get precise data   about your software delivery performance might not be worth the initial   investment. Instead, it might be better to start with having conversations,   taking the DORA Quick Check, or using a source-available or commercial product   that comes with pre-built integrations.</p> </li> </ul>"},{"location":"live-dora-metrics-dashboards/#consequences","title":"Consequences","text":"<p>Maintenance: The dashboard will require ongoing maintenance, especially with regards to data source integrations and ensuring the ETL pipelines are functioning properly.</p>"},{"location":"live-dora-metrics-dashboards/#next-steps","title":"Next Steps","text":"<p>We believe we should gather information about two kinds of approaches:</p> <ol> <li> <p>Build: We can build the dashboard from scratch.</p> </li> <li> <p>Buy: We can purchase a commercial dashboard solution.</p> </li> </ol> <p>If we choose to build, then we believe the steps would be:</p> <ol> <li> <p>Build the frontend dashboard with real-time visualizations of test metrics.</p> </li> <li> <p>Develop the RESTful API to serve data to the frontend.</p> </li> <li> <p>Implement the ETL pipelines for collecting data from the various sources.</p> </li> <li> <p>Deploy the system by using CI/CD and ideally targeting a public cloud.</p> </li> </ol>"},{"location":"live-dora-metrics-dashboards/#recommendation-decision-outcome","title":"Recommendation - Decision Outcome","text":"<p>TODO</p>"},{"location":"meta-decisions/lint/","title":"Lint","text":"<p>Status: first sketch, work in progress, request for collaboration</p> <p>Date: Updated 2025-04-04</p> <p>Governance: Chris &amp; Joel for now because this is so lightweight.</p>"},{"location":"meta-decisions/lint/#context","title":"Context","text":"<p>We want to use a lint program for our documentation, because it's helpful if there's an automatic lint step that checks our work for common mistakes.</p>"},{"location":"meta-decisions/lint/#drivers","title":"Drivers","text":"<p>Broadly, we want use lint programs in many ways to improve quality.</p> <p>Specifically, we want to add a lint tool:</p> <ul> <li> <p>Right now.</p> </li> <li> <p>Installable locally so we're not sending data elsewhere.</p> </li> <li> <p>For VS Code because we both use it</p> </li> <li> <p>With a good rating in the VS Code marketplace.</p> </li> <li> <p>Focusing on our immediate need for writing markdown.</p> </li> <li> <p>With a configuration file that we can check into this git repository.</p> </li> </ul>"},{"location":"meta-decisions/lint/#assessment-considered-options","title":"Assessment - Considered Options","text":""},{"location":"meta-decisions/lint/#markdownlint","title":"markdownlint","text":"<p>https://marketplace.visualstudio.com/items?itemName=DavidAnson.vscode-markdownlint</p> <p>It focuses on markdown, and is very popular.</p> <p>It's fast and configurable, and the configuration file can be checked into a git repository as a file <code>.markdownlint.json</code> so it's usable by all the people who use the repo with VS Code or any other editor that uses the same file.</p>"},{"location":"meta-decisions/lint/#trunkio","title":"trunk.io","text":"<p>https://marketplace.visualstudio.com/items?itemName=trunk.io</p> <p>It handles many languages simultaneously.</p> <p>It offers many more features than linting.</p> <p>TODO learn more about this.</p>"},{"location":"meta-decisions/lint/#recommendation-decision-outcome","title":"Recommendation - Decision Outcome","text":"<p>Adopt markdownlint for right now.</p> <p>Commit the file <code>.markdownlint.json</code> to the top level of this repo.</p> <p>Revisit if/when a teammate is ready to research if there's something better.</p>"},{"location":"meta-decisions/mermaid-for-diagrams/","title":"Use Mermaid for Diagrams","text":"<p>Pending Approval</p> <p>Awaiting approval</p> <p>Status: pending Date: 16/05/2025 Governance: Drafted for approval</p>"},{"location":"meta-decisions/mermaid-for-diagrams/#situation-context-and-problem-statement","title":"Situation - Context and Problem Statement","text":"<p>We require a standardised and maintainable method for embedding diagrams within our Architecture Decision Records (ADRs). Currently, diagrams are created using a variety of tools and methods, leading to inconsistencies in style, difficulties in updating, and challenges with version controlling these visual assets alongside the textual documentation. This ad-hoc approach hinders the clarity and long-term maintainability of our architectural documentation.</p>"},{"location":"meta-decisions/mermaid-for-diagrams/#background-decision-drivers","title":"Background - Decision Drivers","text":"<ul> <li>Version Control: Diagrams should be easily version-controlled alongside     the ADR markdown files.</li> <li>Developer Experience: Need for a low-friction method for developers to     create, view, and update diagrams.</li> <li>Consistency: Desire for a uniform look and feel for diagrams across all     records.</li> <li>Accessibility: Diagrams should be easily viewable by all team members     without requiring specialised licensed software.</li> <li>Maintainability: Diagrams should be easy to update as the architecture     evolves.</li> </ul>"},{"location":"meta-decisions/mermaid-for-diagrams/#assessment-considered-options","title":"Assessment - Considered Options","text":"<ul> <li>Mermaid</li> <li>PlantUML</li> <li>draw.io (diagrams.net)</li> </ul>"},{"location":"meta-decisions/mermaid-for-diagrams/#recommendation-decision-outcome","title":"Recommendation - Decision Outcome","text":"<p>Chosen Option: Mermaid</p> <p>We will use Mermaid for creating and embedding diagrams in our Architecture Decision Records.</p> <p>Info</p> <p>To enhance accessibility for screen readers, always include <code>accTitle</code> (a short, descriptive title) and <code>accDescr</code> (a longer description) within your Mermaid diagram code blocks.</p> <p>This provides context for users who cannot see the visual diagram.</p> <p>For more details, see Mermaid Accessibility - accTitle and accDescr.</p> <p>Tip</p> <p>Install the Markdown Preview Mermaid Support VS Code Extension to preview diagrams when editing Markdown files in VS Code.</p>"},{"location":"meta-decisions/mermaid-for-diagrams/#justification","title":"Justification","text":"<p>Mermaid is chosen due to its excellent integration with Markdown-based documentation systems like MkDocs, which we use. Its \"diagrams as code\" approach allows diagrams to be stored as text, making them inherently version-controllable alongside the ADR content. The syntax is relatively simple for common diagram types (flowcharts, sequence diagrams, class diagrams, state diagrams, etc.), lowering the barrier to entry for team members. This approach reduces reliance on external tools for creation and viewing, and helps ensure diagrams are kept up-to-date as they are co-located with the descriptive text.</p>"},{"location":"meta-decisions/mermaid-for-diagrams/#consequences","title":"Consequences","text":"<ul> <li>Good, because diagrams can be diffed and version-controlled effectively with Git.</li> <li>Good, because it simplifies the toolchain for documentation, as diagrams render directly in our documentation portal.</li> <li>Good, because it encourages consistency in diagramming style and notation.</li> <li>Good, because lots of tooling exists (e.g. VS Code extensions)</li> <li>Bad, because Mermaid's capabilities for very complex diagrams or highly specific styling are limited compared to dedicated GUI tools.</li> <li>Bad, because team members will need to learn the Mermaid syntax, which may present an initial learning curve.</li> <li>Neutral, because the rendering of complex diagrams might sometimes require careful structuring of the Mermaid code.</li> </ul>"},{"location":"meta-decisions/mermaid-for-diagrams/#confirmation","title":"Confirmation","text":"<p>Compliance will be confirmed by:</p> <ul> <li>Reviewing new and updated ADRs to ensure diagrams are created using Mermaid.</li> <li>Ensuring our MkDocs build successfully renders Mermaid diagrams.</li> <li>Periodically checking for consistency and clarity of diagrams in the documentation.</li> </ul>"},{"location":"meta-decisions/mermaid-for-diagrams/#pros-and-cons-of-the-options","title":"Pros and Cons of the Options","text":""},{"location":"meta-decisions/mermaid-for-diagrams/#mermaid","title":"Mermaid","text":"<p>Mermaid is a Javascript-based diagramming and charting tool that renders Markdown-inspired text definitions to create and modify diagrams dynamically.</p> <ul> <li>Good, because it's text-based, enabling \"diagrams as code\" and straightforward version control.</li> <li>Good, because it integrates seamlessly with Markdown and is widely supported (e.g., GitHub, GitLab, MkDocs via plugins).</li> <li>Good, because it has a relatively simple and intuitive syntax for common diagram types.</li> <li>Good, because diagrams render directly in browsers or Markdown previews, often without needing separate tools for viewing.</li> <li>Good, because it encourages diagrams to be updated along with the documentation text.</li> <li>Bad, because it offers limited layout control and customization compared to GUI tools or PlantUML.</li> <li>Bad, because it may not support very complex or niche diagram types as comprehensively as other tools.</li> <li>Bad, because extremely complex diagrams can become difficult to write and maintain in text.</li> </ul>"},{"location":"meta-decisions/mermaid-for-diagrams/#plantuml","title":"PlantUML","text":"<p>PlantUML is an open-source tool that uses a simple textual description language to create UML diagrams and a variety of other software development-related diagrams.</p> <ul> <li>Good, because it's text-based (\"diagrams as code\"), excellent for version control.</li> <li>Good, because it supports a very wide range of UML diagrams and many other diagram types.</li> <li>Good, because it offers more powerful layout algorithms and styling options compared to Mermaid.</li> <li>Good, because it has a large, active community and extensive documentation.</li> <li>Bad, because its syntax can be more verbose and complex than Mermaid's, especially for simpler diagrams.</li> <li>Bad, because rendering often requires a local Java installation and generation step, or a dedicated server, although IDE integrations exist.</li> <li>Bad, because integration into Markdown-centric static site generators like MkDocs can be more involved (e.g., requiring specific plugins and potentially a Java runtime on the build server).</li> </ul>"},{"location":"meta-decisions/mermaid-for-diagrams/#drawio-diagramsnet","title":"draw.io (diagrams.net)","text":"<p>draw.io (now diagrams.net) is a free, open-source, web-based and desktop diagramming application.</p> <ul> <li>Good, because it's a powerful and flexible GUI-based diagramming tool with a drag-and-drop interface.</li> <li>Good, because it supports a vast array of diagram types, shapes, and customization options.</li> <li>Good, because it has a user-friendly interface, making it accessible for users who prefer visual tools.</li> <li>Good, because it can export to various formats (PNG, SVG, PDF, XML) and allows embedding diagrams in web pages.</li> <li>Bad, because diagrams are typically stored as binary files (e.g., <code>.drawio</code> which is XML but not easily human-readable for diffs, or image files like <code>.png</code>, <code>.svg</code>) which are difficult to diff and merge meaningfully in version control.</li> <li>Bad, because updating diagrams often involves a manual export/import cycle, making it less integrated with the \"docs as code\" workflow.</li> <li>Bad, because it can lead to inconsistencies in style and formatting across different diagrams and authors if not strictly managed with templates.</li> <li>Neutral, because while <code>.drawio</code> files are XML, their diffs are generally not helpful for understanding visual changes.</li> </ul>"},{"location":"meta-decisions/mermaid-for-diagrams/#example","title":"Example","text":"<p>See Material for MkDocs Diagram support</p> <p>Below is an example flowchart diagram embedded in this record:</p> <pre><code>graph LR\n  accTitle: Example flowchart diagram\n  accDescr {\n      A simple flowchart diagram with points A, B, C and D with a few \n      connections between them to demonstrate the use of Mermaid.\n  }\n  A[Start] --&gt; B{Error?};\n  B --&gt;|Yes| C[Hmm...];\n  C --&gt; D[Debug];\n  D --&gt; B;\n  B ----&gt;|No| E[Yay!];</code></pre>"},{"location":"meta-decisions/site-navigation/","title":"Site Navigation","text":"<p>Status: accepted</p> <p>Date: Updated 2025-04-08</p> <p>Governance: Chris &amp; Joel for now because this is so lightweight.</p>"},{"location":"meta-decisions/site-navigation/#situation-context-and-problem-statement","title":"Situation - Context and Problem Statement","text":"<p>The currently published docs don't have a good structure/navigation and we have a mix of approaches (folders, named files etc). We need to review this and decide an approach.</p>"},{"location":"meta-decisions/site-navigation/#background-decision-drivers","title":"Background - Decision Drivers","text":"<ul> <li>Ideally minimise the need to manually maintain the navigation, accepting this may be unavoidable.</li> <li>We want a solution that provides good flexibility in structure/hierarchy/naming etc.</li> <li>We should have a logical structure for navigation that would make sense to consumers.</li> <li>It would be good to also publish architectural principles, so consider how these could fit in.</li> </ul>"},{"location":"meta-decisions/site-navigation/#joels-learning-from-past-experience","title":"Joel's learning from past experience","text":"<p>I have a very-strong preference for always using a topic folder. This is earned learning thanks to many clients. It's the least-worst solution I've found in practice, for a bunch of reasons.</p> <p>I have a moderately-strong preference for always using a file index.*, which makes the work highly compatible with web services.</p> <p>GitHub doesn't do automatic rendering of the index.md file, even when there's no README.md file. My opinion is this is a problem with GitHub, and is easy enough to fix with a symlink, though the symlink sometimes (50%?) have subpar UI effects in other pipeline tooling.</p> <p>I do many projects where the index file format isn't markdown. The most common for web documentation is index.html, for web APIs is index.json, for web data is index.tsv, for databases is index.sql, etc. In my experience this pattern scales really well.</p> <p>I have a moderate preference for all folders using kebab-lower-case-plural by default, because this works especially well for web slugs, autocomplete, AI ingestion, etc.</p> <p>GitHub is notoriously bad about sorting by case-sensitive first, which IMHO is a UI/UX bug.</p> <p>I do use many exceptions though, if a project/platform/language uses conventions, such as Apple XCode using \"FooBars\" word case no spaces, or Rust Axum using \"foo_bars\" snake case, or JavaScript Express using singular camel case \"fooBar\".</p>"},{"location":"meta-decisions/site-navigation/#assessment-considered-options","title":"Assessment - Considered Options","text":"<p>In order to keep the index.md/README.md in a folder structure approach and sticking with MkDocs, after some research it looks like we will need to manually set/maintain the navigation, this can be done natively in MkDocs config but it has some limitations (e.g. won't show anything that isn't manually added to the nav explicitly); therefore we should consider MkDocs plugins - assessed below:</p>"},{"location":"meta-decisions/site-navigation/#mkdocs-literate-nav","title":"mkdocs-literate-nav","text":"<p>mkdocs-literate-nav - lets you create a <code>SUMMARY.md</code> file containing the name in the <code>doc/</code> folder itself e.g.</p> <pre><code>* [Alpha](alpha.md)\n* [Beta](beta.md)\n* [Delta](delta/index.md)\n    * [Bar](delta/bar.md)\n    * [Foo](delta/foo.md)\n</code></pre> <p>You can also nest <code>SUMMARY.md</code> files, so each sub-folder can maintain its own nav structure if desired. Also allows for parts of the nav to be manually set and other parts to be auto-populated based on folder/structure etc. and supports wildcards.</p> <p>Because the Nav is in Markdown it would also render in GitHub.</p>"},{"location":"meta-decisions/site-navigation/#mkdocs-awesome-nav","title":"mkdocs-awesome-nav","text":"<p>mkdocs-awesome-nav - Similar to literal nav but nav is configured via YAML files.</p> <pre><code>sort:\n  sections: mixed\n\nnav:\n  - About:\n    - Getting Started: index.md\n    - philosophy.md\n    - migration-v3.md\n  - \"*\"\n</code></pre> <p>Looks to offer more configuration/flexibility, such as automatic sorting of pages and also 'flattening' of structure - which would help with the one folder per document preference.</p>"},{"location":"meta-decisions/site-navigation/#recommendation-decision-outcome","title":"Recommendation - Decision Outcome","text":"<ol> <li>Adopt the mkdocs-awesome-nav plugin as it does everything we need, including flattening navigation</li> <li>Enable MkDocs headers and footers in the published site to make navigation easier</li> <li>Set top level headings such as Home, Decision, Principles, Values</li> <li>Flatten the nav to remove empty nested items as needed</li> <li>Determine a logical structure and evolve over time as need records are added</li> </ol>"},{"location":"meta-decisions/spell/","title":"Spell","text":"<p>Status: first sketch, work in progress, request for collaboration</p> <p>Date: Updated 2025-04-04</p> <p>Governance: Chris &amp; Joel for now because this is so lightweight.</p>"},{"location":"meta-decisions/spell/#context","title":"Context","text":"<p>We want to use a spell check program for our documentation, because it's helpful if there's an automatic spell check step that checks our work for common mistakes.</p>"},{"location":"meta-decisions/spell/#drivers","title":"Drivers","text":"<p>Broadly, we want use spell programs in many ways to improve quality.</p> <p>Specifically, we want to add a spell tool:</p> <ul> <li> <p>Right now.</p> </li> <li> <p>Installable locally so we're not sending data elsewhere.</p> </li> <li> <p>For VS Code because we both use it</p> </li> <li> <p>With a good rating in the VS Code marketplace.</p> </li> <li> <p>Focusing on our immediate need for writing markdown.</p> </li> <li> <p>With a configuration file that we can check into this git repository.</p> </li> </ul>"},{"location":"meta-decisions/spell/#assessment","title":"Assessment","text":""},{"location":"meta-decisions/spell/#cspell","title":"cspell","text":"<p>https://cspell.org/</p> <p>The CSpell mono-repo, a spell checker for code.</p> <p>This also offers a cspell command-line application, and related tools.</p> <p>It's fast and configurable, and the configuration file can be checked into a git repository, such as as a file <code>cspell.json</code>, so it's usable by all the people who use the repo with VS Code or any other editor that uses the same file.</p> <p>It can use custom dictionaries.</p>"},{"location":"meta-decisions/spell/#spelling-checker-for-visual-studio-code","title":"Spelling Checker for Visual Studio Code","text":"<p>https://marketplace.visualstudio.com/items?itemName=streetsidesoftware.code-spell-checker</p> <p>A basic spell checker that works well with code and documents.</p> <p>The goal of this spell checker is to help catch common spelling errors while keeping the number of false positives low.</p> <p>This tool leverages cspell as above.</p>"},{"location":"meta-decisions/spell/#recommendation-decision-outcome","title":"Recommendation - Decision Outcome","text":"<p>Adopt cspell for right now.</p> <p>Commit the file <code>cspell.json</code> to the top level of this repo.</p> <p>Revisit if/when a teammate is ready to research if there's something better.</p>"},{"location":"python-script-runner/","title":"python script runner","text":"<p>Status: WIP + RFC + adopting now for pragmatic trial/pilot/PoC</p> <p>Date: 2025-03-31</p> <p>Governance: To Be Discovered; potentially a combo of this repo participants, DHCW CISO, NHS Wales UCB peers, etc.</p>"},{"location":"python-script-runner/#situation-context-and-problem-statement","title":"Situation - Context and Problem Statement","text":"<p>Generally we are aiming for software engineering to use the python programming language for many needs, such as general purpose scripting, system administration, test automation, AI/ML interconnection, etc.</p> <p>Specifically we are aiming to make it fast and easy for python programmers to run python scripts that are standalone and as self-supporting as reasonably possible. For example this means a typical one-file python script that can download its own dependencies, create its own virtual environments, and run itseflf from the command line.</p>"},{"location":"python-script-runner/#background-decision-drivers","title":"Background - Decision Drivers","text":"<p>Python has a long history of many ways to launch it that are incompatible, many kinds of dependency management that are incompatible, and many kinds of virtual environment managers that are incompatible. As far as we know, there is no perfect way to write a standalone self-supporting python script. </p> <p>Therefore we aim to get as close as reasonably possible, using good modern tooling and good modern practices. We're willing to accept some up-front setup, such as ensuring that a system already has a current runtime python and current runtime manager.</p> <p>Scope:</p> <ul> <li> <p>In scope: single-file python scripts (or a small set of files that are python scripts and any related files such as assets) that don't use a python package manager.</p> </li> <li> <p>Out of scope: any larger-scale python projects, such as multi-file python scripts that already have a requirements.txt file, or a python package that's deployable with pip, or a python notebook such as in Jupyter, or a python web app such as with Django, etc.</p> </li> </ul> <p>Background reading:</p> <ul> <li> <p>Self-contained python scripts with uv</p> </li> <li> <p>Self-contained python scripts with uv - discussion on Hacker News)</p> </li> <li> <p>Python specifications: inline script metadata</p> </li> </ul>"},{"location":"python-script-runner/#givens","title":"Givens","text":"<p>At previous clients, Joel evaluated <code>pip</code>, <code>pipx</code>, <code>poetry</code>, <code>uv</code>, by trying them in real use on real projects that had significant needs such as for AI, cloud services, and test automation. Joel chose uv because it provides more-reliable dependency version management, more-batteries-included capabilities, and much faster speed; Digital Health and Care Wales could do a separate architecture decision record for choosing uv, if there's anyone that feels that there's a better choice or a strong need to consider other choices.</p> <p>\"The whole point of uv is to solve the nightmare that is running a script with the right version of python with the right dependencies. \"Just use the system python\" gets you right back to the start such as, oh no! It didn't parse because it used python 3.11 features and I'm still on 3.6.\"</p>"},{"location":"python-script-runner/#assessment-considered-options","title":"Assessment - Considered Options","text":"<p>Options so far:</p> <ul> <li> <p>uv with inline script metadata </p> </li> <li> <p>uv execute runner</p> </li> <li> <p>nuitka compiler</p> </li> </ul>"},{"location":"python-script-runner/#option-uv-with-inline-script-metadata","title":"Option: uv with inline script metadata","text":"<p>To launch a python script that's as self-supporting as reasonable possible, use this the code, as described in the link above:</p> <p>File <code>example.py</code>:</p> <pre><code>#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \"&gt;=3.13\"\n# dependencies = [\n#   \"alfa&gt;=1\", \n#   \"bravo&gt;=2\", \n#   \"charlie&gt;=3\",\n# ]\n# ///\nimport alfa\nimport bravo\nimport charlie\n</code></pre> <p>Change to be executable:</p> <pre><code>chmod +x example.py\n</code></pre> <p>Run:</p> <pre><code>./example.py\n</code></pre> <p>Caveats thanks to discussion:</p> <ul> <li> <p>The script requires uv to already be installed. Arguably you could make it a shell script that checks if uv is already installed and then installs it via curlpipe if not... but that's quite a bit of extra boilerplate and the curlpipe pattern is bad. \u2026 Installing uv will become less of an issue as package managers include uv in their repositories. For example, uv is already available in Alpine Linux and Homebrew: https://repology.org/project/uv/versions.</p> </li> <li> <p>Inline script metadata is a Python standard. When there is no uv on the system and uv isn't packaged but you have the right version of Python for the script, you can run the script with pipx: https://pipx.pypa.io/stable/examples/#pipx-run-examples. pipx is much more widely packaged: https://repology.org/project/pipx/versions.</p> </li> <li> <p>Auto-creating a venv somewhere in your home directory is not really self-contained. If you run the script as a one-off and then delete it, that venv is still there, taking up space. I can't find any assertion in the uv docs that these temporary virtual environments are ever automatically cleaned up.</p> </li> <li> <p>This technique doesn't change the semantics of the code itself, it just changes the environment in which the code runs. In that respect it is no different from a <code>#!/bin/bash</code> comment at the top of a shell script.</p> </li> <li> <p>The showstopper for us is our SCA vulnerability scanner doesn't work with uv yet. You can add an intermediate sca stage that exports the uv dependencies as requirements.txt.</p> </li> <li> <p>Windows doesn't support shebang lines as you probably know, but if you associate uv with .py files you'll get the same result. I think it should be something like this: <code>ftype Python.File=C:\\Path\\to\\uv.exe run %L %*</code>. If you don't use the CPython installer the Python.File file type might not be defined, so you might need to set that with <code>assoc</code> first: <code>assoc .py=Python.File</code>.</p> </li> </ul>"},{"location":"python-script-runner/#option-uv-execute-runner","title":"Option: uv execute runner","text":"<p>From discussion:</p> <p>I have my own uv execute script:</p> <p>File <code>uve</code>:</p> <pre><code>#!/bin/bash\ntemp=$(mktemp)\ntrap 'unlink $temp' EXIT\nuv export --script $1 --no-hashes &gt; $temp\nuv run --with-requirements $temp vim $1\n</code></pre>"},{"location":"python-script-runner/#option-nuitka-compiler","title":"Option: nuitka compiler","text":"<p>From discussion.</p> <p>For those who want a really self-contained Python script, I'd like to point out the Nuitka compiler. </p> <p>I've been using it in production for my gRPC services with no issues whatsoever - just \"nuitka --onefile run.py\" and that's it. It Just Werks. </p> <p>Since it's a compiler, the resulting binary is even faster than the original Python program would be if it were bundled via Pyinstaller.</p> <p>https://nuitka.net/</p> <p>https://github.com/kayhayen</p>"},{"location":"python-script-runner/#recommendation-decision-outcome","title":"Recommendation - Decision Outcome","text":"<p>Adopt.</p> <p>Revisit periodically, such as when there are new capabilities for <code>uv</code>, or new launching options for <code>python</code>, or new defaults for busybox or Alpine.</p> <p>Cautions thanks to the original article:</p> <ul> <li> <p>Be aware the virtual environment is not created/resolved before running. This means that you won't get linting/autocomplete properly for the environment.</p> </li> <li> <p>Be aware that the <code>-S</code> flag depends on coreutils env, which isn't available by default on some systems, such as the busybox env that you get when using default Alpine. One workaround is to install GNU <code>coreutils</code> in your container, or to install <code>uutils-coreutils</code> for a more lightweight implementation in Rust.</p> </li> </ul>"},{"location":"terminology-services/","title":"Terminology services","text":"<p>Note</p> <p>Work in Progress</p> <p>Status: first sketch, work in progress, request for collaboration</p> <p>Date: Updated 2025-04-06</p> <p>Governance: To Be Discovered; potentially a combo of this repo partipants, DHCW CISO, NHS Wales UCB peers, etc.</p>"},{"location":"terminology-services/#context","title":"Context","text":"<p>Broadly, many of our medical applications provide many kinds search capabilities, such as medical terminology search for procedure names and codes, prescription  names and codes, location names and codes, etc. A typical example is a clinician using a medical application who wants to search for the medication \"paracetamol\", and find the medication code, or synonyms such as \"acetaminophen\", or specific SKUs such as for a specific brands or specific dose.</p> <p>Broadly, this is the use case: As a clinician, I want to search for the medication \"paracetamol\", and I want the search to work well, using typical good search practices, and see results that include the best matches for medical use.</p> <ul> <li> <p>Autocorrect search such as \"porocitimel\" because spell check helps, especially   for harder-to-spell works, and for English-as-an-successive-language speakers.</p> </li> <li> <p>Synonym search \"acetaminophen\" because this is a synonym and a more-common   name some countries.</p> </li> <li> <p>Code search such as \"41833511000001106\" because this is SCTID code for a   specific kind and dose.</p> </li> <li> <p>Scan code such as a barcode or QR code because these can be printed on paper,   or bottles, or boxes, etc.</p> </li> <li> <p>Results that include more-general answers, such as the more-general category   of painkillers.</p> </li> <li> <p>Results that include more-specific answers, such as the more-specific category   of pediatric paracetamol.</p> </li> <li> <p>Results with sibling answers with differences, such as returning the sibling   painkiller \"aspirin\", pluse with differences noted such as \"not recommended   for people older than X or younger than Y or who are pregnant\". We anticipate   that this is a large research area that is beyond this ADR scope.</p> </li> </ul> <p>Specifically right now, the emergency department module authentication needs some kind of plan for authentication using \"multi-party authentication\" (MPA) which is historically known as the \"two-person rule\" (2PR). Our current understanding is that there's a medical must-have requirement to have two clinicians do simultaneous authentication in real-time during high-risk treatments, procedures, prescriptions, etc.</p>"},{"location":"terminology-services/#drivers","title":"Drivers","text":"<p>We currently believe the fastest/simplest/best path to the emergency department module (EDM) proof of capability (PoC) for multi-party authentication (MPA) is to skip building it into the app, and instead making an API call to external terminology services, such as a SNOMED service, or MPA-compliance service, etc.</p> <p>We want to align with industry standards (not reinvent the wheel).</p> <p>We want to get good-enough quality work in place now, so we can try it out, ask for feedback, and get help.</p> <p>We have recently seen mostly-working prototypes of terminology services, including two written by NHS clinicians, that are very close to having this capability. These prototypes also seem to demonstrate that there's not yet any DHCW solution or NHS Wales solution that covers this use case well.</p> <p>We believe that terminology services do not, and must not, contain any personally-identifying information, user-specific information, medically-sensitive information, etc. This means terminology services are excellent candidates for external services, such as DCHW building a free open source tool, or DHCW buying Software as a Service APIs from a vendor, or some kind of hybrid.</p> <p>We need to validate our understanding of all the above.</p>"},{"location":"terminology-services/#assessment","title":"Assessment","text":"<p>We intend to assess at least three kinds of options, and timebox our assessment of these kinds to just a few hours per kind:</p> <ol> <li> <p>Build. This means building our our terminology services at DHCW, using our    new ways of working in the cloud, with modern practices, automatic testing,    etc.</p> </li> <li> <p>Buy. This means paying a vendor for terminology services, including the    search API, using either a medical-specific vendor such as for SNOMED codes,    or a global generic vendor such as for faceted search.</p> </li> <li> <p>Brief. This means we'd code a \"brief\", which is a quick placeholder that    demonstrates the use case, and drives discussion forward. The purpose of    doing a brief is a short-duration summary of the facts, to help instruct and    inform the chain-of-command. The goal of this brief would be to justify more    work, funding, testing, etc.</p> </li> </ol>"},{"location":"terminology-services/#recommendation-decision-outcome","title":"Recommendation - Decision Outcome","text":"<p>TODO</p>"},{"location":"united-kingdom-national-cyber-security-centre/","title":"United Kingdom (UK) National Cyber Security Centre (NCSC)","text":"<p>Status: first sketch, work in progress, request for collaboration</p> <p>Date: Updated 2025-04-04</p> <p>Governance: To Be Discovered; potentially a combo of this repo participants, UK NHS Wales DHCW CISO, UK NHS Wales UCB peers, etc.</p>"},{"location":"united-kingdom-national-cyber-security-centre/#situation-context-and-problem-statement","title":"Situation - Context and Problem Statement","text":"<p>Broadly, we want cyber-security for our organisation, our various services, our open source, etc.</p> <p>Narrowly, we want the emergency department module authentication example to have good cyber-security practices from the get go.</p>"},{"location":"united-kingdom-national-cyber-security-centre/#background-decision-drivers","title":"Background - Decision Drivers","text":"<p>NHS Wales has a variety of cyber-security practices, such as those being driven by the various university health boards and trusts.</p> <p>NHS Wales groups are in conversation with the United Kingdom (UK) National Cyber Security Centre (NCSC). For example, the NHS Wales DHCW CISO Deputy has regular meetings with UK NCSC, and Joel met (2025-03-27) with Alex at UK NCSC to discuss overall cyber-security.</p> <p>Alex describes that UK NCSC is advisory-only, not regulatory. Joel is currently unclear where the regulatory side of things is.</p>"},{"location":"united-kingdom-national-cyber-security-centre/#assessment-considered-options","title":"Assessment - Considered Options","text":"<p>Alex at NCSC has suggested multiple options for us to consider:</p> <ul> <li> <p>\\1. NCSC can provide a cyber-security assessment of our organisation, which we can then use to improve our cyber-security practices. Alex is going to send along more information about how this would work. There's extensive information on the NCSC website about this.</p> </li> <li> <p>\\1.a. NCSC can do this with each NHS Wales group separately.</p> </li> <li> <p>\\1.b. NCSC can do this with all the NHS Wales groups all together.</p> </li> <li> <p>\\2. In parallel, NHS Wales staff (e.g. Joel, Chris, etc.) can join the NCSC, in variuos ways.</p> </li> <li> <p>\\2.a. NCSC Slack channel, which involves 300+ security-related people who are advising the teams, requesting features, reporting issues, etc.</p> </li> <li> <p>\\2.b. NCSC planning-- unclear what this means-- need more info; it sounds somewhat like UK Government Design System team.</p> </li> <li> <p>\\3. NCSC has change management processes where DHCW (e.g. Joel, Chris, CISO, etc.) can request changes to the NCSC programs, in order of priority.</p> </li> <li> <p>\\3.a. Add recommendation for coordinated vulnerability disclosure.</p> </li> <li> <p>\\3.b. Replace HackerOne with a UK national security provider and/or with peer-to-peer PGP/GPG keys.</p> </li> <li> <p>\\3.c. Add recommendation for website footer \"Security Policy\".</p> </li> </ul>"},{"location":"united-kingdom-national-cyber-security-centre/#recommendation-decision-outcome","title":"Recommendation - Decision Outcome","text":"<p>WIP. Currently, Joel is focusing on learning more about options 1.a., 2.a., 3.a.</p>"},{"location":"ways-of-working/","title":"Ways Of Working (WOW)","text":"<p>Note</p> <p>Work in Progress</p> <p>Status: first sketch, work in progress, request for collaboration</p> <p>Date: 2025-03-21</p> <p>Governance: To Be Discovered; potentially a combo of this repo partipants, DHCW CISO, NHS Wales UCB peers, etc.</p>"},{"location":"ways-of-working/#situation-context-and-problem-statement","title":"Situation - Context and Problem Statement","text":"<ul> <li> <p>We want to encourage high-trust high-speed participation in our org and our repos, and help shape what good participation can look like, rather than just a blank slate.</p> </li> <li> <p>Broadly this is known as our \"ways of working\", and some people and companies may also know this as a mix of principles, values, whys, tenets, ground rules, aspirations, norms, working agreements, culture, etc.</p> </li> </ul>"},{"location":"ways-of-working/#background-decision-drivers","title":"Background - Decision Drivers","text":"<ul> <li> <p>We want to get good-enough quality work in place now, so we can try it out, ask for feedback, get help with it with Capacitas consultants who have two more weeks with us, etc.</p> </li> <li> <p>We want to align with industry standards (not reinvent the wheel).</p> </li> </ul>"},{"location":"ways-of-working/#assessment-considered-options","title":"Assessment - Considered Options","text":"<p>For immediate ship, we want to align with what we know works well broadly (which Joel has) and what works well for NHS (which NHS England has):</p> <ul> <li> <p>Ways of Working \u2013 Joel's many-year multi-client aggregation.</p> </li> <li> <p>NHS England GitHub ways of working</p> </li> </ul> <p>To expand this ADR during the work-in-progress, here are a bunch of additional options, and we could/should add more as we discover them:</p> <ul> <li> <p>Team Norms, Working Agreements, and Simple Rules by Esther Derby</p> </li> <li> <p>Working Agreements by Jane Haskell</p> </li> <li> <p>Adult Principles by John Perry Barlow</p> </li> <li> <p>Principles by Nabeel S. Qureshi</p> </li> <li> <p>Ground rules at Tesla by Elon Musk</p> </li> <li> <p>Ground Rules by Tree Bressen</p> </li> <li> <p>Ground rules for effective meetings by Get The Picture</p> </li> <li> <p>High-velocity decision making by Amazon</p> </li> <li> <p>How to send progress updates by Slava Akhmechet</p> </li> <li> <p>How we structure our work and teams at Basecamp</p> </li> <li> <p>Leadership Principles by United States Marine Corps</p> </li> <li> <p>Project management practices by Hacker News participants</p> </li> <li> <p>Rules of the Road by Jerry Perenchio</p> </li> <li> <p>Scaled Agile Framework (SAFe)</p> </li> <li> <p>Software Engineering at Google</p> </li> <li> <p>Software working advice by Cyranix</p> </li> <li> <p>Team working agreements example by giffconstable</p> </li> <li> <p>The Core Protocols by McCarthy</p> </li> <li> <p>The Five Keys to a Successful Google Team</p> </li> <li> <p>The unwritten laws of engineering at Stedi</p> </li> <li> <p>Engineering management checklist by Patrick Newman</p> </li> <li> <p>Strategies to improve workplace communication - By Calm Business</p> </li> <li> <p>Onboarding and induction checklist - By employmenthero</p> </li> <li> <p>Our Values - What it Means to Work at ZOE</p> </li> <li> <p>101 Additional Advices by Kevin Kelly</p> </li> </ul>"},{"location":"ways-of-working/#recommendation-decision-outcome","title":"Recommendation - Decision Outcome","text":"<p>Adopt a ways-of-working repository, taking elements of the NHS England existing work, Joel's existing work, and any feedback as we go.</p> <ul> <li> <p>We start now, and iterate as we learn-- this is likely to be especially true for small tuning thanks to CISO participation for the emergency department authentication project ASAP.</p> </li> <li> <p>We understand that NHS England is significantly ahead of NHS Wales with this kind of work, so we have catch up to do, and some of the wording may need simplification or more explanation.</p> </li> <li> <p>We anticipate that no one will actually care much about this for a while, because it's just docs and checklists; the goal is to get a few points on the scoreboard, not boil the oceans.</p> </li> </ul>"}]}